{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyaJzZlc3_2T",
        "outputId": "22721df0-cc4d-4a16-e0a6-8e41b2743f15"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hwoSh6133-JK"
      },
      "outputs": [],
      "source": [
        "# all relevant libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsMJZGvy3-JO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CpYy05tQ3-JP"
      },
      "outputs": [],
      "source": [
        "#path1 = \"../Data/features_30_sec.csv\"\n",
        "path2 = '/content/drive/MyDrive/GTZAN/Data/features_30_sec.csv'\n",
        "dataset = pd.read_csv(path2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NL60GfB3-JQ",
        "outputId": "05c4dd17-54b1-4907-c2bc-8af3d39f815d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['filename', 'length', 'chroma_stft_mean', 'chroma_stft_var', 'rms_mean', 'rms_var', 'spectral_centroid_mean', 'spectral_centroid_var', 'spectral_bandwidth_mean', 'spectral_bandwidth_var', 'rolloff_mean', 'rolloff_var', 'zero_crossing_rate_mean', 'zero_crossing_rate_var', 'harmony_mean', 'harmony_var', 'perceptr_mean', 'perceptr_var', 'tempo', 'mfcc1_mean', 'mfcc1_var', 'mfcc2_mean', 'mfcc2_var', 'mfcc3_mean', 'mfcc3_var', 'mfcc4_mean', 'mfcc4_var', 'mfcc5_mean', 'mfcc5_var', 'mfcc6_mean', 'mfcc6_var', 'mfcc7_mean', 'mfcc7_var', 'mfcc8_mean', 'mfcc8_var', 'mfcc9_mean', 'mfcc9_var', 'mfcc10_mean', 'mfcc10_var', 'mfcc11_mean', 'mfcc11_var', 'mfcc12_mean', 'mfcc12_var', 'mfcc13_mean', 'mfcc13_var', 'mfcc14_mean', 'mfcc14_var', 'mfcc15_mean', 'mfcc15_var', 'mfcc16_mean', 'mfcc16_var', 'mfcc17_mean', 'mfcc17_var', 'mfcc18_mean', 'mfcc18_var', 'mfcc19_mean', 'mfcc19_var', 'mfcc20_mean', 'mfcc20_var', 'label']\n"
          ]
        }
      ],
      "source": [
        "header_row = dataset.columns.tolist()\n",
        "print(header_row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXu1NbMz3-JR",
        "outputId": "503328c1-3f88-4ead-8d50-2f925c962f55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     mfcc1_mean     mfcc1_var  mfcc2_mean   mfcc2_var  mfcc3_mean   mfcc3_var   \n",
            "0   -113.570648   2564.207520  121.571793  295.913818  -19.168142  235.574432  \\\n",
            "1   -207.501694   7764.555176  123.991264  560.259949    8.955127  572.810913   \n",
            "2    -90.722595   3319.044922  140.446304  508.765045  -29.093889  411.781219   \n",
            "3   -199.544205   5507.517090  150.090897  456.505402    5.662678  257.161163   \n",
            "4   -160.337708   5195.291992  126.219635  853.784729  -35.587811  333.792938   \n",
            "..          ...           ...         ...         ...         ...         ...   \n",
            "995 -153.640961   2540.949463  109.864647  455.579956  -23.065695  189.883865   \n",
            "996 -142.392029   3282.358887  116.189629  345.518890  -32.147167  191.464813   \n",
            "997 -124.952271   1681.638794  115.177155  475.088074  -47.975151  290.302795   \n",
            "998 -225.007751  10766.367188  123.646751  492.819122   -9.724174  605.487488   \n",
            "999 -235.161972   7712.194336  123.870110  798.665283  -22.538395  518.708618   \n",
            "\n",
            "     mfcc4_mean   mfcc4_var  mfcc5_mean   mfcc5_var  ...  mfcc16_mean   \n",
            "0     42.366421  151.106873   -6.364664  167.934799  ...     0.752740  \\\n",
            "1     35.877647  264.506104    2.907320  279.932922  ...     0.927998   \n",
            "2     31.684334  144.090317  -13.984504  155.493759  ...     2.451690   \n",
            "3     26.859079  158.267303    1.771399  268.034393  ...     0.780874   \n",
            "4     22.148071  193.456100  -32.478600  336.276825  ...    -4.520576   \n",
            "..          ...         ...         ...         ...  ...          ...   \n",
            "995   59.050125  132.334518   -7.475873   92.553497  ...     1.789867   \n",
            "996   49.117840   66.674255   -8.373376   81.370674  ...     3.739020   \n",
            "997   52.814674  113.682693  -13.484810   77.294281  ...     1.838090   \n",
            "998   56.605164  189.945770   10.436500  156.834641  ...    -2.812176   \n",
            "999   52.939743  228.190399   -1.444669  182.343460  ...     1.794104   \n",
            "\n",
            "     mfcc16_var  mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var   \n",
            "0     52.420910    -1.690215   36.524071    -0.408979   41.597103  \\\n",
            "1     55.356403    -0.731125   60.314529     0.295073   48.120598   \n",
            "2     40.598766    -7.729093   47.639427    -1.816407   52.382141   \n",
            "3     44.427753    -3.319597   50.206673     0.636965   37.319130   \n",
            "4     86.099236    -5.454034   75.269707    -0.916874   53.613918   \n",
            "..          ...          ...         ...          ...         ...   \n",
            "995   45.050526   -13.289984   41.754955     2.484145   36.778877   \n",
            "996   33.851742   -10.848309   39.395096     1.881229   32.010040   \n",
            "997   33.597008   -12.845291   36.367264     3.440978   36.001110   \n",
            "998   46.324894    -4.416050   43.583942     1.556207   34.331261   \n",
            "999   59.167755    -7.069775   73.760391     0.028346   76.504326   \n",
            "\n",
            "     mfcc19_mean  mfcc19_var  mfcc20_mean  mfcc20_var  \n",
            "0      -2.303523   55.062923     1.221291   46.936035  \n",
            "1      -0.283518   51.106190     0.531217   45.786282  \n",
            "2      -3.439720   46.639660    -2.231258   30.573025  \n",
            "3      -0.619121   37.259739    -3.407448   31.949339  \n",
            "4      -4.404827   62.910812   -11.703234   55.195160  \n",
            "..           ...         ...          ...         ...  \n",
            "995    -6.713265   54.866825    -1.193787   49.950665  \n",
            "996    -7.461491   39.196327    -2.795338   31.773624  \n",
            "997   -12.588070   42.502201    -2.106337   29.865515  \n",
            "998    -5.041897   47.227180    -3.590644   41.299088  \n",
            "999    -2.025783   72.189316     1.155239   49.662510  \n",
            "\n",
            "[1000 rows x 40 columns]\n"
          ]
        }
      ],
      "source": [
        "# Extract the MFCC feature columns\n",
        "mfcc_columns = ['mfcc1_mean', 'mfcc1_var', 'mfcc2_mean', 'mfcc2_var', 'mfcc3_mean', 'mfcc3_var', 'mfcc4_mean', 'mfcc4_var', 'mfcc5_mean', 'mfcc5_var', 'mfcc6_mean', 'mfcc6_var', 'mfcc7_mean', 'mfcc7_var', 'mfcc8_mean', 'mfcc8_var', 'mfcc9_mean', 'mfcc9_var', 'mfcc10_mean', 'mfcc10_var', 'mfcc11_mean', 'mfcc11_var', 'mfcc12_mean', 'mfcc12_var', 'mfcc13_mean', 'mfcc13_var', 'mfcc14_mean', 'mfcc14_var', 'mfcc15_mean', 'mfcc15_var', 'mfcc16_mean', 'mfcc16_var', 'mfcc17_mean', 'mfcc17_var', 'mfcc18_mean', 'mfcc18_var', 'mfcc19_mean', 'mfcc19_var', 'mfcc20_mean', 'mfcc20_var']\n",
        "\n",
        "mfcc_features = dataset[mfcc_columns]\n",
        "\n",
        "# Print the MFCC features\n",
        "print(mfcc_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NQdiCmnh3-JS"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into features and labels\n",
        "columns = ['filename','label']\n",
        "features = dataset.drop(columns=columns, axis=1)  # Drop the 'label' column\n",
        "labels = dataset['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "c_1zIMhi3-JS"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mQdHRfHi3-JT"
      },
      "outputs": [],
      "source": [
        "# Initialize a scaler object\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training features and transform the training features\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Transform the testing features using the fitted scaler\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "s39KROoP3-JU"
      },
      "outputs": [],
      "source": [
        "# Reshape the features to a 3D array [samples, timesteps, features]\n",
        "# Assuming your features have shape (num_samples, num_features)\n",
        "num_timesteps = 1  # Adjust the number of timesteps based on your requirements\n",
        "X_train_reshaped = np.reshape(X_train_scaled, (X_train_scaled.shape[0], num_timesteps, X_train_scaled.shape[1]))\n",
        "X_test_reshaped = np.reshape(X_test_scaled, (X_test_scaled.shape[0], num_timesteps, X_test_scaled.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Yrg3pxp23-JU"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize a label encoder object\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the label encoder on the training labels\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "\n",
        "# Perform the same label encoding on the testing labels\n",
        "y_test_encoded = label_encoder.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sP726zo63-JU",
        "outputId": "64ba061c-74b5-4296-f94b-ff445471416d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "50/50 [==============================] - 2s 3ms/step - loss: 2.0791 - accuracy: 0.3288\n",
            "Epoch 2/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.6115 - accuracy: 0.4387\n",
            "Epoch 3/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.2884 - accuracy: 0.5725\n",
            "Epoch 4/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 1.0573 - accuracy: 0.6675\n",
            "Epoch 5/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.8848 - accuracy: 0.7200\n",
            "Epoch 6/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.7595 - accuracy: 0.7725\n",
            "Epoch 7/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6583 - accuracy: 0.7962\n",
            "Epoch 8/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.8225\n",
            "Epoch 9/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.8562\n",
            "Epoch 10/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.8662\n",
            "Epoch 11/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3783 - accuracy: 0.8900\n",
            "Epoch 12/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3420 - accuracy: 0.8875\n",
            "Epoch 13/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.3000 - accuracy: 0.9087\n",
            "Epoch 14/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2583 - accuracy: 0.9337\n",
            "Epoch 15/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2287 - accuracy: 0.9337\n",
            "Epoch 16/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1993 - accuracy: 0.9538\n",
            "Epoch 17/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1777 - accuracy: 0.9563\n",
            "Epoch 18/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1586 - accuracy: 0.9663\n",
            "Epoch 19/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1383 - accuracy: 0.9712\n",
            "Epoch 20/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1170 - accuracy: 0.9787\n",
            "Epoch 21/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1043 - accuracy: 0.9837\n",
            "Epoch 22/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0940 - accuracy: 0.9862\n",
            "Epoch 23/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0807 - accuracy: 0.9925\n",
            "Epoch 24/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9950\n",
            "Epoch 25/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.9937\n",
            "Epoch 26/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9937\n",
            "Epoch 27/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9950\n",
            "Epoch 28/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0440 - accuracy: 0.9975\n",
            "Epoch 29/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 0.9987\n",
            "Epoch 30/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0354 - accuracy: 0.9975\n",
            "Epoch 31/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0317 - accuracy: 0.9975\n",
            "Epoch 32/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0306 - accuracy: 0.9987\n",
            "Epoch 33/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 0.9987\n",
            "Epoch 34/600\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0251 - accuracy: 0.9975\n",
            "Epoch 35/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0216 - accuracy: 0.9987\n",
            "Epoch 36/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0195 - accuracy: 0.9987\n",
            "Epoch 37/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 0.9987\n",
            "Epoch 38/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 0.9987\n",
            "Epoch 39/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0165 - accuracy: 0.9975\n",
            "Epoch 40/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 0.9975\n",
            "Epoch 41/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 0.9987\n",
            "Epoch 42/600\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0152 - accuracy: 0.9987\n",
            "Epoch 43/600\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.0175 - accuracy: 0.9975\n",
            "Epoch 44/600\n",
            "50/50 [==============================] - 1s 10ms/step - loss: 0.0153 - accuracy: 0.9975\n",
            "Epoch 45/600\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.0118 - accuracy: 0.9975\n",
            "Epoch 46/600\n",
            "50/50 [==============================] - 1s 11ms/step - loss: 0.0105 - accuracy: 0.9987\n",
            "Epoch 47/600\n",
            "50/50 [==============================] - 0s 10ms/step - loss: 0.0114 - accuracy: 0.9987\n",
            "Epoch 48/600\n",
            "50/50 [==============================] - 1s 12ms/step - loss: 0.0102 - accuracy: 0.9975\n",
            "Epoch 49/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.9975\n",
            "Epoch 50/600\n",
            "50/50 [==============================] - 0s 10ms/step - loss: 0.0098 - accuracy: 0.9987\n",
            "Epoch 51/600\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 0.0085 - accuracy: 0.9975\n",
            "Epoch 52/600\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.0099 - accuracy: 0.9975\n",
            "Epoch 53/600\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.0079 - accuracy: 0.9987\n",
            "Epoch 54/600\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 0.9987\n",
            "Epoch 55/600\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0115 - accuracy: 0.9975\n",
            "Epoch 56/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.9987\n",
            "Epoch 57/600\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0097 - accuracy: 0.9975\n",
            "Epoch 58/600\n",
            "50/50 [==============================] - 0s 10ms/step - loss: 0.0087 - accuracy: 0.9975\n",
            "Epoch 59/600\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 0.9975\n",
            "Epoch 60/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.9987\n",
            "Epoch 61/600\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 0.0088 - accuracy: 0.9975\n",
            "Epoch 62/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9975\n",
            "Epoch 63/600\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 0.9987\n",
            "Epoch 64/600\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 0.9987\n",
            "Epoch 65/600\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.0084 - accuracy: 0.9975\n",
            "Epoch 66/600\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 0.9987\n",
            "Epoch 67/600\n",
            "50/50 [==============================] - 0s 10ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 68/600\n",
            "50/50 [==============================] - 1s 10ms/step - loss: 0.0073 - accuracy: 0.9975\n",
            "Epoch 69/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 0.9987\n",
            "Epoch 70/600\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0090 - accuracy: 0.9975\n",
            "Epoch 71/600\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.0073 - accuracy: 0.9975\n",
            "Epoch 72/600\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 0.9987\n",
            "Epoch 73/600\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 0.0063 - accuracy: 0.9975\n",
            "Epoch 74/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.9975\n",
            "Epoch 75/600\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 0.9987\n",
            "Epoch 76/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 0.9975\n",
            "Epoch 77/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 0.9975\n",
            "Epoch 78/600\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 0.9987\n",
            "Epoch 79/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0065 - accuracy: 0.9975\n",
            "Epoch 80/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 0.9987\n",
            "Epoch 81/600\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0091 - accuracy: 0.9975\n",
            "Epoch 82/600\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 0.9987\n",
            "Epoch 83/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 0.9975\n",
            "Epoch 84/600\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 0.0061 - accuracy: 0.9975\n",
            "Epoch 85/600\n",
            "50/50 [==============================] - 1s 11ms/step - loss: 0.0043 - accuracy: 0.9987\n",
            "Epoch 86/600\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.0078 - accuracy: 0.9975\n",
            "Epoch 87/600\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 0.9975\n",
            "Epoch 88/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 0.9975\n",
            "Epoch 89/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9975\n",
            "Epoch 90/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9987\n",
            "Epoch 91/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9975\n",
            "Epoch 92/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 0.9975\n",
            "Epoch 93/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.9987\n",
            "Epoch 94/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9975\n",
            "Epoch 95/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.9975\n",
            "Epoch 96/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9987\n",
            "Epoch 97/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9987\n",
            "Epoch 98/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9987\n",
            "Epoch 99/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 0.9987\n",
            "Epoch 100/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 0.9987\n",
            "Epoch 101/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9987\n",
            "Epoch 102/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 0.9975\n",
            "Epoch 103/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9975\n",
            "Epoch 104/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9987\n",
            "Epoch 105/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9975\n",
            "Epoch 106/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 0.9987\n",
            "Epoch 107/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9987\n",
            "Epoch 108/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9975\n",
            "Epoch 109/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 0.9987\n",
            "Epoch 110/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 0.9987\n",
            "Epoch 111/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 0.9987\n",
            "Epoch 112/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 0.9987\n",
            "Epoch 113/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.9975\n",
            "Epoch 114/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9987\n",
            "Epoch 115/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9975\n",
            "Epoch 116/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 0.9987\n",
            "Epoch 117/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.9975\n",
            "Epoch 118/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 0.9975\n",
            "Epoch 119/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 0.9987\n",
            "Epoch 120/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9975\n",
            "Epoch 121/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9987\n",
            "Epoch 122/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 0.9925\n",
            "Epoch 123/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.9987\n",
            "Epoch 124/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.9975\n",
            "Epoch 125/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9975\n",
            "Epoch 126/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 0.9975\n",
            "Epoch 127/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 0.9987\n",
            "Epoch 128/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.9987\n",
            "Epoch 129/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9975\n",
            "Epoch 130/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.9987\n",
            "Epoch 131/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 0.9975\n",
            "Epoch 132/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9987\n",
            "Epoch 133/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 0.9975\n",
            "Epoch 134/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9975\n",
            "Epoch 135/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 0.9987\n",
            "Epoch 136/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 137/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.9987\n",
            "Epoch 138/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 139/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 140/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 0.9987\n",
            "Epoch 141/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 0.9975\n",
            "Epoch 142/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 0.9987\n",
            "Epoch 143/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9987\n",
            "Epoch 144/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 0.9975\n",
            "Epoch 145/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 0.9975\n",
            "Epoch 146/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 0.9975\n",
            "Epoch 147/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 0.9975\n",
            "Epoch 148/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 0.9975\n",
            "Epoch 149/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 0.9975\n",
            "Epoch 150/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 151/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 0.9975\n",
            "Epoch 152/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.9987\n",
            "Epoch 153/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 0.9975\n",
            "Epoch 154/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 155/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 156/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 0.9975\n",
            "Epoch 157/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 158/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.9987\n",
            "Epoch 159/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9987\n",
            "Epoch 160/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9987\n",
            "Epoch 161/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9987\n",
            "Epoch 162/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.9975\n",
            "Epoch 163/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.9987\n",
            "Epoch 164/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.9975\n",
            "Epoch 165/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 0.9987\n",
            "Epoch 166/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 167/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9975\n",
            "Epoch 168/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 169/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9987\n",
            "Epoch 170/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9987\n",
            "Epoch 171/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 172/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9987\n",
            "Epoch 173/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9987\n",
            "Epoch 174/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 0.9987\n",
            "Epoch 175/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.9987\n",
            "Epoch 176/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 0.9975\n",
            "Epoch 177/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 0.9987\n",
            "Epoch 178/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 0.9987\n",
            "Epoch 179/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 0.9987\n",
            "Epoch 180/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9975\n",
            "Epoch 181/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 182/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9975\n",
            "Epoch 183/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9987\n",
            "Epoch 184/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9975\n",
            "Epoch 185/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 0.9987\n",
            "Epoch 186/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9987\n",
            "Epoch 187/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9975\n",
            "Epoch 188/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9987\n",
            "Epoch 189/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 190/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 0.9987\n",
            "Epoch 191/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9987\n",
            "Epoch 192/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 193/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9975\n",
            "Epoch 194/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9987\n",
            "Epoch 195/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 0.9987\n",
            "Epoch 196/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9975\n",
            "Epoch 197/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 198/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 0.9987\n",
            "Epoch 199/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9975\n",
            "Epoch 200/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 0.9987\n",
            "Epoch 201/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 0.9987\n",
            "Epoch 202/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 0.9987\n",
            "Epoch 203/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 204/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 205/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 0.9975\n",
            "Epoch 206/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 207/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 0.9975\n",
            "Epoch 208/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 209/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.9987\n",
            "Epoch 210/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 211/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 212/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9975\n",
            "Epoch 213/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 0.9987\n",
            "Epoch 214/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9987\n",
            "Epoch 215/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9987\n",
            "Epoch 216/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9987\n",
            "Epoch 217/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 0.9975\n",
            "Epoch 218/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 0.9987\n",
            "Epoch 219/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 0.9987\n",
            "Epoch 220/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9975\n",
            "Epoch 221/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 0.9975\n",
            "Epoch 222/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 0.9987\n",
            "Epoch 223/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9975\n",
            "Epoch 224/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.9987\n",
            "Epoch 225/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 226/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 227/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9987\n",
            "Epoch 228/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.9975\n",
            "Epoch 229/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.9987\n",
            "Epoch 230/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9975\n",
            "Epoch 231/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.9975\n",
            "Epoch 232/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 233/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.9975\n",
            "Epoch 234/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.9975\n",
            "Epoch 235/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.9975\n",
            "Epoch 236/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.9987\n",
            "Epoch 237/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9987\n",
            "Epoch 238/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 239/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.9987\n",
            "Epoch 240/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 241/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 242/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.9987\n",
            "Epoch 243/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.9987\n",
            "Epoch 244/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9975\n",
            "Epoch 245/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 246/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 247/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 0.9987\n",
            "Epoch 248/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.9850\n",
            "Epoch 249/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0782 - accuracy: 0.9775\n",
            "Epoch 250/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.9887\n",
            "Epoch 251/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.9962\n",
            "Epoch 252/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 0.9975\n",
            "Epoch 253/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 254/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 255/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.9975\n",
            "Epoch 256/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 0.9987\n",
            "Epoch 257/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.9975\n",
            "Epoch 258/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.9975\n",
            "Epoch 259/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 260/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9975\n",
            "Epoch 261/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 262/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9987\n",
            "Epoch 263/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 264/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 265/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.9987\n",
            "Epoch 266/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 267/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 0.9975\n",
            "Epoch 268/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 0.9975\n",
            "Epoch 269/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 270/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.9975\n",
            "Epoch 271/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9975\n",
            "Epoch 272/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9975\n",
            "Epoch 273/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9987\n",
            "Epoch 274/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 275/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 276/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9975\n",
            "Epoch 277/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 0.9987\n",
            "Epoch 278/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 279/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 0.9975\n",
            "Epoch 280/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 0.9987\n",
            "Epoch 281/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 0.9987\n",
            "Epoch 282/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 283/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 0.9975\n",
            "Epoch 284/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 285/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 286/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 287/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 288/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 289/600\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 0.9987\n",
            "Epoch 290/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 0.9987\n",
            "Epoch 291/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 292/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9975\n",
            "Epoch 293/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 0.9975\n",
            "Epoch 294/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 295/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 0.9987\n",
            "Epoch 296/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 297/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 0.9975\n",
            "Epoch 298/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 0.9987\n",
            "Epoch 299/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 300/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9975\n",
            "Epoch 301/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 302/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.9975\n",
            "Epoch 303/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9987\n",
            "Epoch 304/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 305/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 306/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9975\n",
            "Epoch 307/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9975\n",
            "Epoch 308/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.9987\n",
            "Epoch 309/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9987\n",
            "Epoch 310/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9987\n",
            "Epoch 311/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9987\n",
            "Epoch 312/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.9987\n",
            "Epoch 313/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9975\n",
            "Epoch 314/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 315/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.9987\n",
            "Epoch 316/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 0.9975\n",
            "Epoch 317/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 318/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 319/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.9975\n",
            "Epoch 320/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 321/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.9975\n",
            "Epoch 322/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 323/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9987\n",
            "Epoch 324/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 325/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 326/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9987\n",
            "Epoch 327/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 328/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 329/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.9987\n",
            "Epoch 330/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 0.9975\n",
            "Epoch 331/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.9987\n",
            "Epoch 332/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 333/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9987\n",
            "Epoch 334/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.9975\n",
            "Epoch 335/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.9975\n",
            "Epoch 336/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 337/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.9987\n",
            "Epoch 338/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 339/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.9975\n",
            "Epoch 340/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 341/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 342/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 343/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 344/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9987\n",
            "Epoch 345/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9987\n",
            "Epoch 346/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9875\n",
            "Epoch 347/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9875\n",
            "Epoch 348/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9937\n",
            "Epoch 349/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.9937\n",
            "Epoch 350/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9975\n",
            "Epoch 351/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.9987\n",
            "Epoch 352/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 353/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 354/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 355/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 356/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 357/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 358/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9987\n",
            "Epoch 359/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 360/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 361/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 362/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9975\n",
            "Epoch 363/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 364/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9987\n",
            "Epoch 365/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9975\n",
            "Epoch 366/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 367/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 368/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 369/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9975\n",
            "Epoch 370/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 371/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 372/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 373/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 374/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 375/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9987\n",
            "Epoch 376/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 377/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9975\n",
            "Epoch 378/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 379/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 380/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 381/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 382/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 383/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 384/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 385/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9987\n",
            "Epoch 386/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 387/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 388/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9975\n",
            "Epoch 389/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 390/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 391/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 392/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 393/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 0.9975\n",
            "Epoch 394/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 395/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 396/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 397/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 398/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 399/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9975\n",
            "Epoch 400/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 401/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 402/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9987\n",
            "Epoch 403/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 404/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 405/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9987\n",
            "Epoch 406/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 407/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9987\n",
            "Epoch 408/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 409/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 410/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 411/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 412/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9987\n",
            "Epoch 413/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9975\n",
            "Epoch 414/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9987\n",
            "Epoch 415/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.9975\n",
            "Epoch 416/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 417/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.9975\n",
            "Epoch 418/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 419/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 420/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9987\n",
            "Epoch 421/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 422/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9975\n",
            "Epoch 423/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 424/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 425/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 426/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 427/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 428/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 429/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 430/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.9975\n",
            "Epoch 431/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 432/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.9987\n",
            "Epoch 433/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9975\n",
            "Epoch 434/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9975\n",
            "Epoch 435/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 436/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 437/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 438/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9987\n",
            "Epoch 439/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9987\n",
            "Epoch 440/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9987\n",
            "Epoch 441/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 442/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9975\n",
            "Epoch 443/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9987\n",
            "Epoch 444/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9987\n",
            "Epoch 445/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 446/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 447/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9987\n",
            "Epoch 448/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 449/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 450/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 451/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9975\n",
            "Epoch 452/600\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 453/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 454/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9975\n",
            "Epoch 455/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 0.9987\n",
            "Epoch 456/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 0.9987\n",
            "Epoch 457/600\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 458/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9975\n",
            "Epoch 459/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 0.9987\n",
            "Epoch 460/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 461/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 462/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 0.9987\n",
            "Epoch 463/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 464/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9975\n",
            "Epoch 465/600\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 0.9987\n",
            "Epoch 466/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 467/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 468/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9975\n",
            "Epoch 469/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 470/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 471/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.9987\n",
            "Epoch 472/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 473/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 474/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 0.9987\n",
            "Epoch 475/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.9975\n",
            "Epoch 476/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 477/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9987\n",
            "Epoch 478/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.9987\n",
            "Epoch 479/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 480/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 481/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.9975\n",
            "Epoch 482/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 483/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 0.9987\n",
            "Epoch 484/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 485/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 486/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9975\n",
            "Epoch 487/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 488/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9975\n",
            "Epoch 489/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 490/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9987\n",
            "Epoch 491/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 492/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 493/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.9975\n",
            "Epoch 494/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 495/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 496/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.9975\n",
            "Epoch 497/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 498/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.9987\n",
            "Epoch 499/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 500/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 501/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 502/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9975\n",
            "Epoch 503/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 504/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9987\n",
            "Epoch 505/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.9987\n",
            "Epoch 506/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9975\n",
            "Epoch 507/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 0.9987\n",
            "Epoch 508/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 509/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9975\n",
            "Epoch 510/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0371 - accuracy: 0.9862\n",
            "Epoch 511/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0498 - accuracy: 0.9862\n",
            "Epoch 512/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0262 - accuracy: 0.9950\n",
            "Epoch 513/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9975\n",
            "Epoch 514/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 0.9987\n",
            "Epoch 515/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9987\n",
            "Epoch 516/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 517/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 518/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9987\n",
            "Epoch 519/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 520/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 521/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 522/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 523/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9975\n",
            "Epoch 524/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 525/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 526/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9987\n",
            "Epoch 527/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 528/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 529/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 530/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9987\n",
            "Epoch 531/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9987\n",
            "Epoch 532/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 533/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 534/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9975\n",
            "Epoch 535/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 536/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9987\n",
            "Epoch 537/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 538/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9987\n",
            "Epoch 539/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9987\n",
            "Epoch 540/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9975\n",
            "Epoch 541/600\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 542/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 0.9987\n",
            "Epoch 543/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 0.9975\n",
            "Epoch 544/600\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 0.9975\n",
            "Epoch 545/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 546/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 0.9975\n",
            "Epoch 547/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 548/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 549/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9987\n",
            "Epoch 550/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 551/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 552/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 553/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 554/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 555/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 556/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.9975\n",
            "Epoch 557/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9987\n",
            "Epoch 558/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 0.9987\n",
            "Epoch 559/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 560/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 561/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 562/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.9975\n",
            "Epoch 563/600\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 0.9975\n",
            "Epoch 564/600\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.0023 - accuracy: 0.9987\n",
            "Epoch 565/600\n",
            "50/50 [==============================] - 1s 16ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 566/600\n",
            "50/50 [==============================] - 1s 11ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 567/600\n",
            "50/50 [==============================] - 1s 11ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 568/600\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 569/600\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 570/600\n",
            "50/50 [==============================] - 1s 13ms/step - loss: 0.0019 - accuracy: 0.9987\n",
            "Epoch 571/600\n",
            "50/50 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 572/600\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 573/600\n",
            "50/50 [==============================] - 1s 14ms/step - loss: 0.0026 - accuracy: 0.9987\n",
            "Epoch 574/600\n",
            "50/50 [==============================] - 1s 10ms/step - loss: 0.0023 - accuracy: 0.9987\n",
            "Epoch 575/600\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 576/600\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 0.9987\n",
            "Epoch 577/600\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.0021 - accuracy: 0.9975\n",
            "Epoch 578/600\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 579/600\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 0.9987\n",
            "Epoch 580/600\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 581/600\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 582/600\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 0.0023 - accuracy: 0.9975\n",
            "Epoch 583/600\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.9987\n",
            "Epoch 584/600\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.9987\n",
            "Epoch 585/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9975\n",
            "Epoch 586/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9975\n",
            "Epoch 587/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9987\n",
            "Epoch 588/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9975\n",
            "Epoch 589/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 590/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9987\n",
            "Epoch 591/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9987\n",
            "Epoch 592/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9975\n",
            "Epoch 593/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9987\n",
            "Epoch 594/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9987\n",
            "Epoch 595/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9975\n",
            "Epoch 596/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9987\n",
            "Epoch 597/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9987\n",
            "Epoch 598/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9975\n",
            "Epoch 599/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9987\n",
            "Epoch 600/600\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 0.9975\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=64, input_shape=(num_timesteps, X_train_reshaped.shape[2])))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dense(units=len(labels.unique()), activation='softmax'))  # Adjust the output units based on the number of classes\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_reshaped, y_train_encoded, epochs=600, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test_reshaped)  # Make predictions on the scaled test data\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "accuracy = accuracy_score(y_test_encoded, y_pred_labels)  # Calculate accuracy\n",
        "report = classification_report(y_test_encoded, y_pred_labels)  # Generate a detailed classification report\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puU4SERi5iqU",
        "outputId": "3e379ddd-d983-42a6-b71a-a536216f3181"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.71\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.70      0.68        20\n",
            "           1       0.87      1.00      0.93        13\n",
            "           2       0.65      0.63      0.64        27\n",
            "           3       0.65      0.52      0.58        21\n",
            "           4       0.59      0.87      0.70        15\n",
            "           5       0.89      0.77      0.83        22\n",
            "           6       0.81      0.88      0.85        25\n",
            "           7       0.67      0.77      0.71        13\n",
            "           8       0.65      0.48      0.55        23\n",
            "           9       0.67      0.67      0.67        21\n",
            "\n",
            "    accuracy                           0.71       200\n",
            "   macro avg       0.71      0.73      0.71       200\n",
            "weighted avg       0.71      0.71      0.71       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "hAzIokWI3-JV",
        "outputId": "36ca7bb3-e3cc-420e-d592-fd5c25aa5f55"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABBDklEQVR4nO3deXxU1f3/8fckIZMEsgBZgbAICAiyCIKBKvQLFZBSQPp1KZbFViviQtFfFRdAWxupVWnVgmgF11L1K6gIKqJoRZRFUEBkUQgISQAhG0tCkvP743YmBMIW7swJk9fz8ZjHzF3mzmcOw+Q959zFY4wxAgAACBFhtgsAAABwE+EGAACEFMINAAAIKYQbAAAQUgg3AAAgpBBuAABASCHcAACAkEK4AQAAIYVwAwAAQgrhBkDAjR49Ws2bN6/Wc6dMmSKPx+NuQQBCGuEGqMU8Hs9p3ZYsWWK7VCtGjx6tevXq2S4DwBnycG0poPZ66aWXKk2/8MILWrRokV588cVK83/2s58pJSWl2q9z5MgRlZeXy+v1nvFzS0tLVVpaqqioqGq/fnWNHj1ar7/+uoqKioL+2gCqL8J2AQDsue666ypNf/7551q0aNFx84918OBBxcTEnPbr1KlTp1r1SVJERIQiIviqAnD6GJYCcFJ9+vRRhw4dtGrVKl122WWKiYnRPffcI0l68803NWjQIDVq1Eher1ctW7bUH//4R5WVlVXaxrH73Gzbtk0ej0d//etfNXPmTLVs2VJer1cXX3yxVqxYUem5Ve1z4/F4dMstt2jevHnq0KGDvF6v2rdvr3ffffe4+pcsWaJu3bopKipKLVu21NNPP+36fjyvvfaaunbtqujoaCUmJuq6667Tzp07K62Tk5OjMWPGqEmTJvJ6vUpLS9OQIUO0bds2/zorV65U//79lZiYqOjoaLVo0ULXX3+9a3UCtQU/hwCc0o8//qiBAwfqmmuu0XXXXecfopo9e7bq1aunCRMmqF69evrwww81adIkFRQU6JFHHjnldl955RUVFhbqd7/7nTwej/7yl7/oyiuv1Pfff3/K3p5PP/1Ub7zxhm6++WbFxsbq73//u4YPH67t27erYcOGkqTVq1drwIABSktL0wMPPKCysjI9+OCDSkpKOvtG+a/Zs2drzJgxuvjii5WZmanc3Fz97W9/09KlS7V69WolJCRIkoYPH67169fr1ltvVfPmzbV7924tWrRI27dv909ffvnlSkpK0t13362EhARt27ZNb7zxhmu1ArWGAYD/GjdunDn2a6F3795GkpkxY8Zx6x88ePC4eb/73e9MTEyMOXz4sH/eqFGjTLNmzfzTW7duNZJMw4YNzb59+/zz33zzTSPJvP322/55kydPPq4mSSYyMtJs2bLFP++rr74ykswTTzzhnzd48GATExNjdu7c6Z+3efNmExERcdw2qzJq1ChTt27dEy4vKSkxycnJpkOHDubQoUP++fPnzzeSzKRJk4wxxuzfv99IMo888sgJtzV37lwjyaxYseKUdQE4OYalAJyS1+vVmDFjjpsfHR3tf1xYWKi9e/fq0ksv1cGDB/Xtt9+ecrtXX3216tev75++9NJLJUnff//9KZ/br18/tWzZ0j/dsWNHxcXF+Z9bVlamDz74QEOHDlWjRo3867Vq1UoDBw485fZPx8qVK7V7927dfPPNlXZ4HjRokNq2bat33nlHktNOkZGRWrJkifbv31/ltnw9PPPnz9eRI0dcqQ+orQg3AE6pcePGioyMPG7++vXrNWzYMMXHxysuLk5JSUn+nZHz8/NPud2mTZtWmvYFnRMFgJM91/d833N3796tQ4cOqVWrVsetV9W86sjKypIktWnT5rhlbdu29S/3er2aOnWqFi5cqJSUFF122WX6y1/+opycHP/6vXv31vDhw/XAAw8oMTFRQ4YM0axZs1RcXOxKrUBtQrgBcEpH99D45OXlqXfv3vrqq6/04IMP6u2339aiRYs0depUSVJ5efkptxseHl7lfHMaZ6g4m+faMH78eG3atEmZmZmKiorS/fffr3bt2mn16tWSnJ2kX3/9dS1btky33HKLdu7cqeuvv15du3blUHTgDBFuAFTLkiVL9OOPP2r27Nm6/fbb9fOf/1z9+vWrNMxkU3JysqKiorRly5bjllU1rzqaNWsmSdq4ceNxyzZu3Ohf7tOyZUvdcccdev/997Vu3TqVlJTo0UcfrbTOJZdcooceekgrV67Uyy+/rPXr12vOnDmu1AvUFoQbANXi6zk5uqekpKRE//jHP2yVVEl4eLj69eunefPmadeuXf75W7Zs0cKFC115jW7duik5OVkzZsyoNHy0cOFCbdiwQYMGDZLknBfo8OHDlZ7bsmVLxcbG+p+3f//+43qdOnfuLEkMTQFniEPBAVRLz549Vb9+fY0aNUq33XabPB6PXnzxxRo1LDRlyhS9//776tWrl8aOHauysjI9+eST6tChg9asWXNa2zhy5Ij+9Kc/HTe/QYMGuvnmmzV16lSNGTNGvXv31rXXXus/FLx58+b6/e9/L0natGmT+vbtq6uuukoXXHCBIiIiNHfuXOXm5uqaa66RJD3//PP6xz/+oWHDhqlly5YqLCzUM888o7i4OF1xxRWutQlQGxBuAFRLw4YNNX/+fN1xxx267777VL9+fV133XXq27ev+vfvb7s8SVLXrl21cOFC3Xnnnbr//vuVnp6uBx98UBs2bDito7kkpzfq/vvvP25+y5YtdfPNN2v06NGKiYnRww8/rLvuukt169bVsGHDNHXqVP8RUOnp6br22mu1ePFivfjii4qIiFDbtm316quvavjw4ZKcHYqXL1+uOXPmKDc3V/Hx8erevbtefvlltWjRwrU2AWoDri0FoNYZOnSo1q9fr82bN9suBUAAsM8NgJB26NChStObN2/WggUL1KdPHzsFAQg4em4AhLS0tDSNHj1a5513nrKysjR9+nQVFxdr9erVat26te3yAAQA+9wACGkDBgzQv/71L+Xk5Mjr9SojI0N//vOfCTZACKPnBgAAhBT2uQEAACGFcAMAAEJKrdvnpry8XLt27VJsbKw8Ho/tcgAAwGkwxqiwsFCNGjVSWNjJ+2ZqXbjZtWuX0tPTbZcBAACqYceOHWrSpMlJ16l14SY2NlaS0zhxcXGWqwEAAKejoKBA6enp/r/jJ1Prwo1vKCouLo5wAwDAOeZ0dilhh2IAABBSCDcAACCkEG4AAEBIqXX73AAA7CgvL1dJSYntMlCDRUZGnvIw79NBuAEABFxJSYm2bt2q8vJy26WgBgsLC1OLFi0UGRl5Vtsh3AAAAsoYo+zsbIWHhys9Pd2VX+YIPb6T7GZnZ6tp06ZndaJdwg0AIKBKS0t18OBBNWrUSDExMbbLQQ2WlJSkXbt2qbS0VHXq1Kn2dojPAICAKisrk6SzHmpA6PN9Rnyfmeoi3AAAgoLr+eFU3PqMEG4AAEBIIdwAABAkzZs317Rp0057/SVLlsjj8SgvLy9gNYUiwg0AAMfweDwnvU2ZMqVa212xYoVuvPHG016/Z8+eys7OVnx8fLVe73SFWojiaCmXFBdLublSWJh0iiuxAwBquOzsbP/jf//735o0aZI2btzon1evXj3/Y2OMysrKFBFx6j+pSUlJZ1RHZGSkUlNTz+g5oOfGNatWSc2aSX362K4EAHC2UlNT/bf4+Hh5PB7/9LfffqvY2FgtXLhQXbt2ldfr1aeffqrvvvtOQ4YMUUpKiurVq6eLL75YH3zwQaXtHjss5fF49Oyzz2rYsGGKiYlR69at9dZbb/mXH9ujMnv2bCUkJOi9995Tu3btVK9ePQ0YMKBSGCstLdVtt92mhIQENWzYUHfddZdGjRqloUOHVrs99u/fr5EjR6p+/fqKiYnRwIEDtXnzZv/yrKwsDR48WPXr11fdunXVvn17LViwwP/cESNGKCkpSdHR0WrdurVmzZpV7VpOB+HGJb5zUp3l0WsAEPKMkQ4csHMzxr33cffdd+vhhx/Whg0b1LFjRxUVFemKK67Q4sWLtXr1ag0YMECDBw/W9u3bT7qdBx54QFdddZW+/vprXXHFFRoxYoT27dt3wvUPHjyov/71r3rxxRf1ySefaPv27brzzjv9y6dOnaqXX35Zs2bN0tKlS1VQUKB58+ad1XsdPXq0Vq5cqbfeekvLli2TMUZXXHGFjhw5IkkaN26ciouL9cknn2jt2rWaOnWqv3fr/vvv1zfffKOFCxdqw4YNmj59uhITE8+qnlMytUx+fr6RZPLz813d7vLlxkjGNG3q6mYB4Jx36NAh880335hDhw4ZY4wpKnK+L23ciorOvP5Zs2aZ+Ph4//RHH31kJJl58+ad8rnt27c3TzzxhH+6WbNm5vHHH/dPSzL33Xeff7qoqMhIMgsXLqz0Wvv37/fXIsls2bLF/5ynnnrKpKSk+KdTUlLMI4884p8uLS01TZs2NUOGDDlhnce+ztE2bdpkJJmlS5f65+3du9dER0ebV1991RhjzIUXXmimTJlS5bYHDx5sxowZc8LXPtqxn5Wjncnfb3puXELPDQDULt26das0XVRUpDvvvFPt2rVTQkKC6tWrpw0bNpyy56Zjx47+x3Xr1lVcXJx27959wvVjYmLUsmVL/3RaWpp//fz8fOXm5qp79+7+5eHh4eratesZvbejbdiwQREREerRo4d/XsOGDdWmTRtt2LBBknTbbbfpT3/6k3r16qXJkyfr66+/9q87duxYzZkzR507d9Yf/vAHffbZZ9Wu5XQRblwSHu7cE24A4ORiYqSiIjs3N6/+ULdu3UrTd955p+bOnas///nP+s9//qM1a9bowgsvPOWV0I+9zIDH4znpBUarWt+4Od5WDb/97W/1/fff69e//rXWrl2rbt266YknnpAkDRw4UFlZWfr973+vXbt2qW/fvpWG0QKBcOMSX7jhgrcAcHIej1S3rp1bIE+SvHTpUo0ePVrDhg3ThRdeqNTUVG3bti1wL1iF+Ph4paSkaMWKFf55ZWVl+vLLL6u9zXbt2qm0tFRffPGFf96PP/6ojRs36oILLvDPS09P10033aQ33nhDd9xxh5555hn/sqSkJI0aNUovvfSSpk2bppkzZ1a7ntPBoeAuYVgKAGq31q1b64033tDgwYPl8Xh0//33n7QHJlBuvfVWZWZmqlWrVmrbtq2eeOIJ7d+//7QubbB27VrFxsb6pz0ejzp16qQhQ4bohhtu0NNPP63Y2Fjdfffdaty4sYYMGSJJGj9+vAYOHKjzzz9f+/fv10cffaR27dpJkiZNmqSuXbuqffv2Ki4u1vz58/3LAoVw4xJ6bgCgdnvsscd0/fXXq2fPnkpMTNRdd92lgoKCoNdx1113KScnRyNHjlR4eLhuvPFG9e/fX+G+P1Qncdlll1WaDg8PV2lpqWbNmqXbb79dP//5z1VSUqLLLrtMCxYs8A+RlZWVady4cfrhhx8UFxenAQMG6PHHH5fknKtn4sSJ2rZtm6Kjo3XppZdqzpw57r/xo3iM7YG6ICsoKFB8fLzy8/MVFxfn2nY3bZLatJHi4qT8fNc2CwDnvMOHD2vr1q1q0aKFoqKibJdT65SXl6tdu3a66qqr9Mc//tF2OSd1ss/Kmfz9trrPTWZmpi6++GLFxsYqOTlZQ4cOrXQGyBN57bXX1LZtW0VFRenCCy/0nyjIJnpuAAA1QVZWlp555hlt2rRJa9eu1dixY7V161b96le/sl1a0FgNNx9//LHGjRunzz//XIsWLdKRI0d0+eWX68CBAyd8zmeffaZrr71Wv/nNb7R69WoNHTpUQ4cO1bp164JY+fHY5wYAUBOEhYVp9uzZuvjii9WrVy+tXbtWH3zwQcD3c6lJatSw1J49e5ScnKyPP/74uHE/n6uvvloHDhzQ/Pnz/fMuueQSde7cWTNmzDjlawRqWGr7dufyC16vdPiwa5sFgHMew1I4XSExLHWs/P/urNKgQYMTrrNs2TL169ev0rz+/ftr2bJlAa3tVOi5AQCgZqgxR0uVl5dr/Pjx6tWrlzp06HDC9XJycpSSklJpXkpKinJycqpcv7i4WMXFxf7pQO25zj43AHByNWigADWUW5+RGtNzM27cOK1bt871w8MyMzMVHx/vv6Wnp7u6fZ+jww3/fwGggu8Q5FOdqRfwfUZO57D1k6kRPTe33HKL5s+fr08++URNmjQ56bqpqanKzc2tNC83N1epqalVrj9x4kRNmDDBP11QUBCQgBN2VEwsL68IOwBQ20VERCgmJkZ79uxRnTp1FBZWY35XowYpLy/Xnj17FBMTo4iIs4snVsONMUa33nqr5s6dqyVLlqhFixanfE5GRoYWL16s8ePH++ctWrRIGRkZVa7v9Xrl9XrdKvmEjg4zhBsAqODxeJSWlqatW7cqKyvLdjmowcLCwtS0adPTOpvyyVgNN+PGjdMrr7yiN998U7Gxsf79ZuLj4xUdHS1JGjlypBo3bqzMzExJ0u23367evXvr0Ucf1aBBgzRnzhytXLky4NepOJWjf4iUlUnHXNcMAGq1yMhItW7dmqEpnFRkZKQrPXtWw8306dMlSX369Kk0f9asWRo9erQkafv27ZXeaM+ePfXKK6/ovvvu0z333KPWrVtr3rx5J90JORiO7bkBAFQWFhbGoeAIihp1nptgCNR5bg4edK4467yGdNR1xwAAwFk6Z89zcy6j5wYAgJqBcOOSY/e5AQAAdhBuXELPDQAANQPhxiX03AAAUDMQblzkCzj03AAAYA/hxkW+oSl6bgAAsIdw4yKuDA4AgH2EGxdxZXAAAOwj3LiInhsAAOwj3LiInhsAAOwj3LiInhsAAOwj3LiInhsAAOwj3LiIQ8EBALCPcOMiTuIHAIB9hBsX0XMDAIB9hBsX0XMDAIB9hBsX0XMDAIB9hBsX0XMDAIB9hBsX0XMDAIB9hBsXcRI/AADsI9y4iJP4AQBgH+HGRQxLAQBgH+HGRexQDACAfYQbF9FzAwCAfYQbF9FzAwCAfYQbF9FzAwCAfYQbF9FzAwCAfYQbF9FzAwCAfYQbF9FzAwCAfYQbF9FzAwCAfYQbFxFuAACwj3DjIoalAACwj3DjInpuAACwj3DjInpuAACwj3DjInpuAACwj3DjInpuAACwj3DjInpuAACwj3DjInpuAACwj3DjInpuAACwj3DjIl+4oecGAAB7CDcu8g1L0XMDAIA9hBsXMSwFAIB9hBsXsUMxAAD2EW5cRM8NAAD2EW5cRM8NAAD2EW5cRM8NAAD2EW5cRM8NAAD2EW5cRM8NAAD2EW5cxEn8AACwj3DjIk7iBwCAfYQbF9FzAwCAfYQbF9FzAwCAfYQbF9FzAwCAfYQbF9FzAwCAfYQbF3EoOAAA9hFuXMRJ/AAAsI9w4yJ6bgAAsI9w46KICOeecAMAgD2EGxf5em5KS+3WAQBAbUa4cZGv54ZwAwCAPYQbFzEsBQCAfYQbF9FzAwCAfYQbF7HPDQAA9hFuXMSwFAAA9hFuXMSwFAAA9hFuXMSwFAAA9hFuXMSwFAAA9hFuXMSwFAAA9hFuXMSwFAAA9hFuXETPDQAA9lkNN5988okGDx6sRo0ayePxaN68eSddf8mSJfJ4PMfdcnJyglPwKbDPDQAA9lkNNwcOHFCnTp301FNPndHzNm7cqOzsbP8tOTk5QBWeGYalAACwL8Lmiw8cOFADBw484+clJycrISHB/YLOEsNSAADYd07uc9O5c2elpaXpZz/7mZYuXWq7HD+GpQAAsM9qz82ZSktL04wZM9StWzcVFxfr2WefVZ8+ffTFF1/ooosuqvI5xcXFKi4u9k8XFBQErD56bgAAsO+cCjdt2rRRmzZt/NM9e/bUd999p8cff1wvvvhilc/JzMzUAw88EJT62OcGAAD7zslhqaN1795dW7ZsOeHyiRMnKj8/33/bsWNHwGphWAoAAPvOqZ6bqqxZs0ZpaWknXO71euX1eoNSC8NSAADYZzXcFBUVVep12bp1q9asWaMGDRqoadOmmjhxonbu3KkXXnhBkjRt2jS1aNFC7du31+HDh/Xss8/qww8/1Pvvv2/rLVTCsBQAAPZZDTcrV67UT3/6U//0hAkTJEmjRo3S7NmzlZ2dre3bt/uXl5SU6I477tDOnTsVExOjjh076oMPPqi0DZsYlgIAwD6PMcbYLiKYCgoKFB8fr/z8fMXFxbm67awsqXlzKTpaOnjQ1U0DAFCrncnf73N+h+KahGEpAADsI9y4iB2KAQCwj3DjIl+4MUYqL7dbCwAAtRXhxkW+YSmJnYoBALCFcOOiiKOOPWNoCgAAOwg3Ljo63NBzAwCAHYQbF9FzAwCAfYQbFx29zw3hBgAAOwg3LgoLkzwe5zHDUgAA2EG4cRnnugEAwC7Cjcs4SzEAAHYRblzGxTMBALCLcOMyhqUAALCLcOMyhqUAALCLcOMyem4AALCLcOMy9rkBAMAuwo3L6LkBAMAuwo3L2OcGAAC7CDcuY1gKAAC7CDcuY1gKAAC7CDcuY1gKAAC7CDcuY1gKAAC7CDcuY1gKAAC7CDcuY1gKAAC7CDcuY1gKAAC7CDcuY1gKAAC7CDcuY1gKAAC7CDcuo+cGAAC7CDcu84WbI0fs1gEAQG1FuHFZZKRzT7gBAMAOwo3L6tRx7gk3AADYQbhxGeEGAAC7CDcuI9wAAGAX4cZlhBsAAOwi3LiMcAMAgF2EG5f5wk1Jid06AACorQg3LuNQcAAA7CLcuIxhKQAA7CLcuIxwAwCAXYQblxFuAACwi3DjMsINAAB2EW5cRrgBAMAuwo3LCDcAANhFuHGZ71BwznMDAIAdhBuX0XMDAIBdhBuXEW4AALCLcOMywg0AAHYRblxGuAEAwC7CjcsINwAA2EW4cRnhBgAAuwg3LvOFGw4FBwDADsKNy3znuaHnBgAAOwg3LmNYCgAAuwg3LiPcAABgF+HGZYQbAADsIty4jHADAIBd1Qo3O3bs0A8//OCfXr58ucaPH6+ZM2e6Vti5inADAIBd1Qo3v/rVr/TRRx9JknJycvSzn/1My5cv17333qsHH3zQ1QLPNRwKDgCAXdUKN+vWrVP37t0lSa+++qo6dOigzz77TC+//LJmz57tZn3nHA4FBwDArmqFmyNHjsjr9UqSPvjgA/3iF7+QJLVt21bZ2dnuVXcO8vXclJc7NwAAEFzVCjft27fXjBkz9J///EeLFi3SgAEDJEm7du1Sw4YNXS3wXOMLNxK9NwAA2FCtcDN16lQ9/fTT6tOnj6699lp16tRJkvTWW2/5h6tqK8INAAB2RVTnSX369NHevXtVUFCg+vXr++ffeOONiomJca24cxHhBgAAu6rVc3Po0CEVFxf7g01WVpamTZumjRs3Kjk52dUCzzURR8VFwg0AAMFXrXAzZMgQvfDCC5KkvLw89ejRQ48++qiGDh2q6dOnu1rgucbjqQg4hBsAAIKvWuHmyy+/1KWXXipJev3115WSkqKsrCy98MIL+vvf/+5qgeci3+HgnOsGAIDgq1a4OXjwoGJjYyVJ77//vq688kqFhYXpkksuUVZWlqsFnov+e5S8iovt1gEAQG1UrXDTqlUrzZs3Tzt27NB7772nyy+/XJK0e/duxcXFuVrguYhwAwCAPdUKN5MmTdKdd96p5s2bq3v37srIyJDk9OJ06dLF1QLPRYQbAADsqdah4L/85S/1k5/8RNnZ2f5z3EhS3759NWzYMNeKO1cRbgAAsKdaPTeSlJqaqi5dumjXrl3+K4R3795dbdu2Pe1tfPLJJxo8eLAaNWokj8ejefPmnfI5S5Ys0UUXXSSv16tWrVrVyGtZEW4AALCnWuGmvLxcDz74oOLj49WsWTM1a9ZMCQkJ+uMf/6jyM7ig0oEDB9SpUyc99dRTp7X+1q1bNWjQIP30pz/VmjVrNH78eP32t7/Ve++9V523ETC+o6UINwAABF+1hqXuvfde/fOf/9TDDz+sXr16SZI+/fRTTZkyRYcPH9ZDDz10WtsZOHCgBg4ceNqvO2PGDLVo0UKPPvqoJKldu3b69NNP9fjjj6t///5n/kYChJ4bAADsqVa4ef755/Xss8/6rwYuSR07dlTjxo118803n3a4OVPLli1Tv379Ks3r37+/xo8ff8LnFBcXq/iolFFQUBCQ2o5GuAEAwJ5qDUvt27evyn1r2rZtq3379p11USeSk5OjlJSUSvNSUlJUUFCgQ4cOVfmczMxMxcfH+2/p6ekBq8+HcAMAgD3VCjedOnXSk08+edz8J598Uh07djzrotw0ceJE5efn+287duwI+Gv6wg1nKAYAIPiqNSz1l7/8RYMGDdIHH3zgP8fNsmXLtGPHDi1YsMDVAo+Wmpqq3NzcSvNyc3MVFxen6OjoKp/j9Xrl9aWNIKHnBgAAe6rVc9O7d29t2rRJw4YNU15envLy8nTllVdq/fr1evHFF92u0S8jI0OLFy+uNG/RokX+gFVTEG4AALCnWj03ktSoUaPjdhz+6quv9M9//lMzZ848rW0UFRVpy5Yt/umtW7dqzZo1atCggZo2baqJEydq586d/iuQ33TTTXryySf1hz/8Qddff70+/PBDvfrqq3rnnXeq+zYCgnADAIA91T6JnxtWrlypLl26+C/ZMGHCBHXp0kWTJk2SJGVnZ2v79u3+9Vu0aKF33nlHixYtUqdOnfToo4/q2WefrVGHgUuEGwAAbKp2z40b+vTpI2PMCZdXdfbhPn36aPXq1QGs6uwRbgAAsMdqz02oItwAAGDPGfXcXHnllSddnpeXdza1hAzCDQAA9pxRuImPjz/l8pEjR55VQaGAa0sBAGDPGYWbWbNmBaqOkELPDQAA9rDPTQAQbgAAsIdwEwCEGwAA7CHcBADXlgIAwB7CTQDQcwMAgD2EmwAg3AAAYA/hJgAINwAA2EO4CQDCDQAA9hBuAoBwAwCAPYSbAIiKcu4PH7ZbBwAAtRHhJgCio537Q4fs1gEAQG1EuAmAmBjn/uBBu3UAAFAbEW4CwNdzc/iwVF5utxYAAGobwk0A+HpuJPa7AQAg2Ag3AeDruZEYmgIAINgINwEQHi5FRjqP2akYAIDgItwEiK/3hp4bAACCi3ATIL79bui5AQAguAg3AULPDQAAdhBuAoSeGwAA7CDcBAg9NwAA2EG4CRB6bgAAsINwEyBcggEAADsINwHCxTMBALCDcBMg9NwAAGAH4SZA6LkBAMAOwk2A0HMDAIAdhJsAoecGAAA7CDcBQs8NAAB2EG4CxBduDhywWwcAALUN4SZA6tVz7ouK7NYBAEBtQ7gJEMINAAB2EG4CJDbWuS8stFsHAAC1DeEmQHzhhp4bAACCi3ATIL5hKXpuAAAILsJNgDAsBQCAHYSbADl6h2Jj7NYCAEBtQrgJEF/PTWmpVFxstxYAAGoTwk2A1K1b8ZidigEACB7CTYBERFRcX4r9bgAACB7CTQBxODgAAMFHuAkgDgcHACD4CDcBxOHgAAAEH+EmgLi+FAAAwUe4CSB6bgAACD7CTQDRcwMAQPARbgKInhsAAIKPcBNAHAoOAEDwEW4CiEPBAQAIPsJNADEsBQBA8BFuAogdigEACD7CTQDRcwMAQPARbgKInhsAAIKPcBNA9NwAABB8hJsA4lBwAACCj3ATQBwKDgBA8BFuAohhKQAAgo9wE0C+npvDh6XSUru1AABQWxBuAsjXcyOx3w0AAMFCuAmgyEgpIsJ5zNAUAADBQbgJII9Hio93HhcU2K0FAIDagnATYAkJzn1ens0qAACoPQg3AeYLN/n5VssAAKDWINwEGD03AAAEF+EmwAg3AAAEF+EmwAg3AAAEF+EmwHxHSxFuAAAIjhoRbp566ik1b95cUVFR6tGjh5YvX37CdWfPni2Px1PpFhUVFcRqzww9NwAABJf1cPPvf/9bEyZM0OTJk/Xll1+qU6dO6t+/v3bv3n3C58TFxSk7O9t/y8rKCmLFZ4ZwAwBAcFkPN4899phuuOEGjRkzRhdccIFmzJihmJgYPffccyd8jsfjUWpqqv+WkpISxIrPDOEGAIDgshpuSkpKtGrVKvXr188/LywsTP369dOyZctO+LyioiI1a9ZM6enpGjJkiNavX3/CdYuLi1VQUFDpFkyEGwAAgstquNm7d6/KysqO63lJSUlRTk5Olc9p06aNnnvuOb355pt66aWXVF5erp49e+qHH36ocv3MzEzFx8f7b+np6a6/j5PxhZv9+4P6sgAA1FrWh6XOVEZGhkaOHKnOnTurd+/eeuONN5SUlKSnn366yvUnTpyo/Px8/23Hjh1BrbdBA+eecAMAQHBE2HzxxMREhYeHKzc3t9L83NxcpaamntY26tSpoy5dumjLli1VLvd6vfJ6vWdda3UlJjr3+/ZJZWVSeLi1UgAAqBWs9txERkaqa9euWrx4sX9eeXm5Fi9erIyMjNPaRllZmdauXau0tLRAlXlWfD03xjgBBwAABJb1YakJEybomWee0fPPP68NGzZo7NixOnDggMaMGSNJGjlypCZOnOhf/8EHH9T777+v77//Xl9++aWuu+46ZWVl6be//a2tt3BSdepI9es7j/futVsLAAC1gdVhKUm6+uqrtWfPHk2aNEk5OTnq3Lmz3n33Xf9Oxtu3b1dYWEUG279/v2644Qbl5OSofv366tq1qz777DNdcMEFtt7CKSUmOvvc7NkjtWtnuxoAAEKbxxhjbBcRTAUFBYqPj1d+fr7i4uKC8pq9ekmffSb93/9JV14ZlJcEACCknMnfb+vDUrWBb6dihqUAAAg8wk0Q+MLNnj126wAAoDYg3ARBUpJzT88NAACBR7gJAoalAAAIHsJNEPh6bhiWAgAg8Ag3QUDPDQAAwUO4CQLCDQAAwUO4CQKGpQAACB7CTRD4em4OHnRuAAAgcAg3QRAbK0VGOo9//NFuLQAAhDrCTRB4PJzIDwCAYCHcBAk7FQMAEByEmyBhp2IAAIKDcBMkaWnO/c6ddusAACDUEW6CpHlz537rVqtlAAAQ8gg3QdKihXNPuAEAILAIN0FCuAEAIDgIN0HiCzfbtknl5VZLAQAgpBFugqRJEyk8XCopkbKzbVcDAEDoItwESUSE1Lix83jHDru1AAAQygg3QZSe7tz/8IPdOgAACGWEmyBq0sS5p+cGAIDAIdwEET03AAAEHuEmiOi5AQAg8Ag3QUTPDQAAgUe4CSJ6bgAACDzCTRD5em6ys6XSUru1AAAQqgg3QZSc7JzvpqxMysmxXQ0AAKGJcBNE4eEVJ/JjvxsAAAKDcBNk7HcDAEBgEW6CjCOmAAAILMJNkNFzAwBAYBFugqxpU+d+2zarZQAAELIIN0F2/vnO/caNdusAACBUEW6CrF07537zZs51AwBAIBBugqxJEykmRjpyRPr+e9vVAAAQegg3QRYWJrVp4zz+9lu7tQAAEIoINxa0bevcE24AAHAf4cYC3343GzbYrQMAgFBEuLGAnhsAAAKHcGPB0eHGGLu1AAAQagg3FrRu7exYnJfH1cEBAHAb4caCqKiKI6ZWrLBbCwAAoYZwY0nPns79Z5/ZrQMAgFBDuLGkVy/nfulSu3UAABBqCDeW+MLNihVScbHdWgAACCWEG0tat5YSE51gs3q17WoAAAgdhBtLPJ6K/W4YmgIAwD2EG4vY7wYAAPcRbizy9dwsW8bJ/AAAcAvhxqKuXaWICOdEfllZtqsBACA0EG4sio6WunRxHi9bZrcWAABCBeHGsowM556T+QEA4A7CjWW+cEPPDQAA7iDcWOYLN2vWSAcPWi0FAICQQLixrGlTKT1dKiuT3nvPdjUAAJz7CDeWeTzSNdc4j194wW4tAACEAsJNDTBypHP/9tvS9u12awEA4FxHuKkBOnSQ/ud/nKGpJ56wXQ0AAOc2wk0Ncfvtzv1LLzkhBwAAVA/hpoYYMECqX985W/FHH9muBjix/fulGTOkfftsVwIAVSPc1BCRkRU7Fk+YIOXlWS0HOKHf/EYaO1a6+WbblQBA1TzG1K5LNhYUFCg+Pl75+fmKi4uzXU4l27ZJrVtLpaVSu3bS+vXO0VRATXL0Z7J2fXsAsOlM/n7Tc1ODNG8uPf+883jDBmnFCqvlAMc5OswQvAHUVISbGuZXv5Kuvtp5zHlvUNNkZ1c8jo21V0dNd+iQ9OabUlGR7UqA2olwUwONGuXc/+Mf0jvv2K0FONq6dRWPCwqkw4ft1VKT3XOPNHSodMMNtitBMOTkSH36SE8/bbsS+BBuaqCBA50dNo2RRoyQtmyxXRHg2Lmz8vSOHXbqqOmmTXPu58yxWgaCZMIE6eOPpZtusl0JfAg3NdS0adIll0j5+c5h4l9/bbsiwPmFerSsLDt11HTR0bYrQLAYU/m6gHv22KsFFQg3NVRkpPR//+dcWPO776SuXaX//V8OEYddx4ab776zU0dNV69exWNOyhnatm+vfM6nlSvt1YIKhJsarFEjadUq6ec/dw4Pf/11KSlJuu8+Z4dFINh8OxSH/febY9Mme7XUZBERFY8ZugttGzdWnibc1Aw1Itw89dRTat68uaKiotSjRw8tX778pOu/9tpratu2raKionThhRdqwYIFQao0+BITpbfekt5/3wk2paXSQw9JcXFS48bOzsfTpztHVt12m7Roke2KA6+sTPrDH7gOlw2+npvLLnPuCTfHKy+vPDTRtSsHBoSyY8MNp/CoGayfxO/f//63Ro4cqRkzZqhHjx6aNm2aXnvtNW3cuFHJycnHrf/ZZ5/psssuU2Zmpn7+85/rlVde0dSpU/Xll1+qQ4cOp3y9mnwSv1M5eFB67TVp8uST7+swcKDUoIHUtq0TjurVc35J1qnjHJ7aqZOz/NAhqU0bqW5dZ/grMtJ5fmKiM4781VdScrLTg1SVnTudo2VatnSmDx+WvN7An//k7belX/zCebxrl5SWFtjXQ4Xzz5c2b5YmTZIefND5/Hz7re2qapa9e50fIkdr2NAJhkf36CA0jBvnHNl66aXSf/7jfB/t2mW7qtB0Jn+/rYebHj166OKLL9aTTz4pSSovL1d6erpuvfVW3X333cetf/XVV+vAgQOaP3++f94ll1yizp07a8aMGad8vXM53PiUlTnBYsMGacECackSJ/gkJkpffHF2Z42tU8f55enbT8DjkVJTnX19fPsRNGvmnE15715n+qKLnB2ffftfNG0qJSQ4Z1lOTZV273a2mZQkRUU59+Hh0tq1znWKunVz1gsLc34FxcY6f0Szs53lTZtKR45IJSVOqHvssYp6W7eWrrzSWd/jcerwep3XyM52Xu/8850gV6+e86UTGenM373bqePgQecWFyfFxzvz4uOl3Fzp+++dkyvu3u2EvPh4570Y42ynbl3pwAGnvWJjne2HhztDEd9847RNerpz2HRSklPHhg3SeedV7HQaG+vMr1On4rwoMTHOe/3xR2nNGqcNevRwwub27U6QbN7ced3oaOd1jXEe+9o7Ksq5eTxScbHz+klJznstLHRep149533s3+/Mr1PHmY6MrHgcHe3sU2CM8wUuOT2EP/uZ83j+fKdtfJ87Y46/HT3f43Hqystz/k2Tkpz5paUVt/Jy5zN05IgzXdU2j952ebnzHhITnbbzPS8+3mlbj8f5XOTlOa9dXOwEjaws5z36ArIvmHs8zvNzcir+3XbudMKcx+N8VsPCnNcvK3Mex8Y6z1m2zPmDl5DgXFLF97X01FPOD4t69ZztRURUbENypn0/MIqLnX/jsjLn8+TxVL5FRTnv+cABZ3mdOhU/YIqKnHXCw516fPUeXbfv5tvewYMV/++jo53XLi+v+CyUlFTeblhYxf8dyVnHN8+37SNHnPe2b9/x9R/92iebV1rqvNe4OKcm37+l7zXy850aGjeu/L137HfgyaZ9n6PiYmc6Lq5yLVXV5fE47VNU5Hz/bN0qPfmkcwHksjLpn/+UWrWq+D491rE/AN2cDuS2z+S1Y2Kc7zk3nTPhpqSkRDExMXr99dc1dOhQ//xRo0YpLy9Pb7755nHPadq0qSZMmKDx48f7502ePFnz5s3TV199ddz6xcXFKvZ9auU0Tnp6+jkdbk5m1Srnj40vKOzfL/3wg/OlfvCg05uTkuJ8UW/Z4nw5NmjgfImz4yNOR1iY87nq00davdp2NTVXly7Sl186Q8eckDO0hYc7P1quucb5N4eUkSF99pm72zyTcGO1k3Tv3r0qKytTSkpKpfkpKSn69gR93Tk5OVWun3PsYRz/lZmZqQceeMCdgs8BXbs6t9Pl+yW9d6/zC+u775wdl9u3l3r2dNZZs8bZ5p49ThDascPpUcjLk5o0cX7VHTjgBKRDh5zeih9+cH4JFRY6v7waNnRe4/Bh576szAlZjRs7XwYFBRXDZD/+6GzL14NSUlLxCzIqSurVy3mNTz916i0rc4ZKSkudXwvFxU6vzXnnOXVt3uxccb2w0OkhMqaip0tyel+io52aDx92fgHn5Tm/4BITnR6cJk2c5WVlFb/cDh1y1q9b16k1L895TxERTt3Nmjn7pOzd62zf12uQnOy8R4/H2V5+vvOrv6TE+VVfXu78WzRr5vz6v+gip4dhxQqnnZo0cXohsrKc+4MHnfaNjnZqql/feZ3Dhyt+/Xu9To/Ojz869frOLpyX57Rb/frO/CNHKnrJSkoqehBiY51fodHR0h13OG2zaJGz79Pixc5zfO0iVf1L1ze/vNypMyHB2eaPPzrtFxFRcZOcAOX1OtNVbe/o7UrOuoWFzrajopxt5uc7n4mSEud9NmjgrFOnjhPSGjRwaj94sHIPk0+DBk6b+4Zbs7Od9350r1F4uPOeCgudWmNinKHae+91lt91l/NjYu9e5/NYUOC0ta9HyveaZWVOncY4r+d7D2Vlx/dWHTrkLKtXz1leWlrxbxcTU/HZ8rVleXlFj6Pv8dHT0dEV7Vlc7EyHh1d8BiIjK3puy8oqenmiopx2LC6u2KZveUSEU09aWtU9br7XP9m8iAjn81dQ4NQUFVXxfsrKKr4XfD2eVQ2Jn6rnQXLeg6/XrLCwch1V1WmM85zoaOc7IjPT6UV+9lnpT39yfjgWF1f0nJ3semxuTgdy22f62vXry6qQHwGeOHGiJkyY4J/29dzA4ftPl5jo3M4/39ln52iXXHLyaVsuush2BbVbw4ZO9ztO7oILpA8+sF0FgqFLF+cUHrDParhJTExUeHi4cnNzK83Pzc1Vampqlc9JTU09o/W9Xq+8Xq87BQMAgBrP6qHgkZGR6tq1qxYvXuyfV15ersWLFysjI6PK52RkZFRaX5IWLVp0wvUBAEDtYn1YasKECRo1apS6deum7t27a9q0aTpw4IDGjBkjSRo5cqQaN26szMxMSdLtt9+u3r1769FHH9WgQYM0Z84crVy5UjNnzrT5NgAAQA1hPdxcffXV2rNnjyZNmqScnBx17txZ7777rn+n4e3btyssrKKDqWfPnnrllVd033336Z577lHr1q01b9680zrHDQAACH3Wz3MTbKFwnhsAAGqbM/n7XSMuvwAAAOAWwg0AAAgphBsAABBSCDcAACCkEG4AAEBIIdwAAICQQrgBAAAhhXADAABCCuEGAACEFOuXXwg23wmZCwoKLFcCAABOl+/v9ulcWKHWhZvCwkJJUnp6uuVKAADAmSosLFR8fPxJ16l115YqLy/Xrl27FBsbK4/H49p2CwoKlJ6erh07dnDNqlOgrc4M7XX6aKvTR1udPtrqzASqvYwxKiwsVKNGjSpdULsqta7nJiwsTE2aNAnY9uPi4vjwnyba6szQXqePtjp9tNXpo63OTCDa61Q9Nj7sUAwAAEIK4QYAAIQUwo1LvF6vJk+eLK/Xa7uUGo+2OjO01+mjrU4fbXX6aKszUxPaq9btUAwAAEIbPTcAACCkEG4AAEBIIdwAAICQQrgBAAAhhXDjkqeeekrNmzdXVFSUevTooeXLl9suKeg++eQTDR48WI0aNZLH49G8efMqLTfGaNKkSUpLS1N0dLT69eunzZs3V1pn3759GjFihOLi4pSQkKDf/OY3KioqCuK7CLzMzExdfPHFio2NVXJysoYOHaqNGzdWWufw4cMaN26cGjZsqHr16mn48OHKzc2ttM727ds1aNAgxcTEKDk5Wf/v//0/lZaWBvOtBMX06dPVsWNH/wnBMjIytHDhQv9y2urEHn74YXk8Ho0fP94/j/ZyTJkyRR6Pp9Ktbdu2/uW00/F27typ6667Tg0bNlR0dLQuvPBCrVy50r+8Rn3HG5y1OXPmmMjISPPcc8+Z9evXmxtuuMEkJCSY3Nxc26UF1YIFC8y9995r3njjDSPJzJ07t9Lyhx9+2MTHx5t58+aZr776yvziF78wLVq0MIcOHfKvM2DAANOpUyfz+eefm//85z+mVatW5tprrw3yOwms/v37m1mzZpl169aZNWvWmCuuuMI0bdrUFBUV+de56aabTHp6ulm8eLFZuXKlueSSS0zPnj39y0tLS02HDh1Mv379zOrVq82CBQtMYmKimThxoo23FFBvvfWWeeedd8ymTZvMxo0bzT333GPq1Klj1q1bZ4yhrU5k+fLlpnnz5qZjx47m9ttv98+nvRyTJ0827du3N9nZ2f7bnj17/Mtpp8r27dtnmjVrZkaPHm2++OIL8/3335v33nvPbNmyxb9OTfqOJ9y4oHv37mbcuHH+6bKyMtOoUSOTmZlpsSq7jg035eXlJjU11TzyyCP+eXl5ecbr9Zp//etfxhhjvvnmGyPJrFixwr/OwoULjcfjMTt37gxa7cG2e/duI8l8/PHHxhinXerUqWNee+01/zobNmwwksyyZcuMMU6QDAsLMzk5Of51pk+fbuLi4kxxcXFw34AF9evXN88++yxtdQKFhYWmdevWZtGiRaZ3797+cEN7VZg8ebLp1KlTlctop+Pddddd5ic/+ckJl9e073iGpc5SSUmJVq1apX79+vnnhYWFqV+/flq2bJnFymqWrVu3Kicnp1I7xcfHq0ePHv52WrZsmRISEtStWzf/Ov369VNYWJi++OKLoNccLPn5+ZKkBg0aSJJWrVqlI0eOVGqrtm3bqmnTppXa6sILL1RKSop/nf79+6ugoEDr168PYvXBVVZWpjlz5ujAgQPKyMigrU5g3LhxGjRoUKV2kfhsHWvz5s1q1KiRzjvvPI0YMULbt2+XRDtV5a233lK3bt30v//7v0pOTlaXLl30zDPP+JfXtO94ws1Z2rt3r8rKyip9wCUpJSVFOTk5lqqqeXxtcbJ2ysnJUXJycqXlERERatCgQci2ZXl5ucaPH69evXqpQ4cOkpx2iIyMVEJCQqV1j22rqtrStyzUrF27VvXq1ZPX69VNN92kuXPn6oILLqCtqjBnzhx9+eWXyszMPG4Z7VWhR48emj17tt59911Nnz5dW7du1aWXXqrCwkLaqQrff/+9pk+frtatW+u9997T2LFjddttt+n555+XVPO+42vdVcGBmmTcuHFat26dPv30U9ul1Ght2rTRmjVrlJ+fr9dff12jRo3Sxx9/bLusGmfHjh26/fbbtWjRIkVFRdkup0YbOHCg/3HHjh3Vo0cPNWvWTK+++qqio6MtVlYzlZeXq1u3bvrzn/8sSerSpYvWrVunGTNmaNSoUZarOx49N2cpMTFR4eHhx+1Fn5ubq9TUVEtV1Ty+tjhZO6Wmpmr37t2VlpeWlmrfvn0h2Za33HKL5s+fr48++khNmjTxz09NTVVJSYny8vIqrX9sW1XVlr5loSYyMlKtWrVS165dlZmZqU6dOulvf/sbbXWMVatWaffu3brooosUERGhiIgIffzxx/r73/+uiIgIpaSk0F4nkJCQoPPPP19btmzhc1WFtLQ0XXDBBZXmtWvXzj+UV9O+4wk3ZykyMlJdu3bV4sWL/fPKy8u1ePFiZWRkWKysZmnRooVSU1MrtVNBQYG++OILfztlZGQoLy9Pq1at8q/z4Ycfqry8XD169Ah6zYFijNEtt9yiuXPn6sMPP1SLFi0qLe/atavq1KlTqa02btyo7du3V2qrtWvXVvqiWLRokeLi4o77AgpF5eXlKi4upq2O0bdvX61du1Zr1qzx37p166YRI0b4H9NeVSsqKtJ3332ntLQ0PldV6NWr13GnrNi0aZOaNWsmqQZ+x7u6e3ItNWfOHOP1es3s2bPNN998Y2688UaTkJBQaS/62qCwsNCsXr3arF692kgyjz32mFm9erXJysoyxjiHCSYkJJg333zTfP3112bIkCFVHibYpUsX88UXX5hPP/3UtG7dOuQOBR87dqyJj483S5YsqXQY6sGDB/3r3HTTTaZp06bmww8/NCtXrjQZGRkmIyPDv9x3GOrll19u1qxZY959912TlJQUkoeh3n333ebjjz82W7duNV9//bW5++67jcfjMe+//74xhrY6laOPljKG9vK54447zJIlS8zWrVvN0qVLTb9+/UxiYqLZvXu3MYZ2Otby5ctNRESEeeihh8zmzZvNyy+/bGJiYsxLL73kX6cmfccTblzyxBNPmKZNm5rIyEjTvXt38/nnn9suKeg++ugjI+m426hRo4wxzqGC999/v0lJSTFer9f07dvXbNy4sdI2fvzxR3PttdeaevXqmbi4ODNmzBhTWFho4d0ETlVtJMnMmjXLv86hQ4fMzTffbOrXr29iYmLMsGHDTHZ2dqXtbNu2zQwcONBER0ebxMREc8cdd5gjR44E+d0E3vXXX2+aNWtmIiMjTVJSkunbt68/2BhDW53KseGG9nJcffXVJi0tzURGRprGjRubq6++utI5W2in47399tumQ4cOxuv1mrZt25qZM2dWWl6TvuM9xhjjbl8QAACAPexzAwAAQgrhBgAAhBTCDQAACCmEGwAAEFIINwAAIKQQbgAAQEgh3AAAgJBCuAFQK3k8Hs2bN892GQACgHADIOhGjx4tj8dz3G3AgAG2SwMQAiJsFwCgdhowYIBmzZpVaZ7X67VUDYBQQs8NACu8Xq9SU1Mr3erXry/JGTKaPn26Bg4cqOjoaJ133nl6/fXXKz1/7dq1+p//+R9FR0erYcOGuvHGG1VUVFRpneeee07t27eX1+tVWlqabrnllkrL9+7dq2HDhikmJkatW7fWW2+95V+2f/9+jRgxQklJSYqOjlbr1q2PC2MAaibCDYAa6f7779fw4cP11VdfacSIEbrmmmu0YcMGSdKBAwfUv39/1a9fXytWrNBrr72mDz74oFJ4mT59usaNG6cbb7xRa9eu1VtvvaVWrVpVeo0HHnhAV111lb7++mtdccUVGjFihPbt2+d//W+++UYLFy7Uhg0bNH36dCUmJgavAQBUn+uX4gSAUxg1apQJDw83devWrXR76KGHjDHOldNvuummSs/p0aOHGTt2rDHGmJkzZ5r69euboqIi//J33nnHhIWFmZycHGOMMY0aNTL33nvvCWuQZO677z7/dFFRkZFkFi5caIwxZvDgwWbMmDHuvGEAQcU+NwCs+OlPf6rp06dXmtegQQP/44yMjErLMjIytGbNGknShg0b1KlTJ9WtW9e/vFevXiovL9fGjRvl8Xi0a9cu9e3b96Q1dOzY0f+4bt26iouL0+7duyVJY8eO1fDhw/Xll1/q8ssv19ChQ9WzZ89qvVcAwUW4AWBF3bp1jxsmckt0dPRprVenTp1K0x6PR+Xl5ZKkgQMHKisrSwsWLNCiRYvUt29fjRs3Tn/9619drxeAu9jnBkCN9Pnnnx833a5dO0lSu3bt9NVXX+nAgQP+5UuXLlVYWJjatGmj2NhYNW/eXIsXLz6rGpKSkjRq1Ci99NJLmjZtmmbOnHlW2wMQHPTcALCiuLhYOTk5leZFRET4d9p97bXX1K1bN/3kJz/Ryy+/rOXLl+uf//ynJGnEiBGaPHmyRo0apSlTpmjPnj269dZb9etf/1opKSmSpClTpuimm25ScnKyBg4cqMLCQi1dulS33nrradU3adIkde3aVe3bt1dxcbHmz5/vD1cAajbCDQAr3n33XaWlpVWa16ZNG3377beSnCOZ5syZo5tvvllpaWn617/+pQsuuECSFBMTo/fee0+33367Lr74YsXExGj48OF67LHH/NsaNWqUDh8+rMcff1x33nmnEhMT9ctf/vK064uMjNTEiRO1bds2RUdH69JLL9WcOXNceOcAAs1jjDG2iwCAo3k8Hs2dO1dDhw61XQqAcxD73AAAgJBCuAEAACGFfW4A1DiMlgM4G/TcAACAkEK4AQAAIYVwAwAAQgrhBgAAhBTCDQAACCmEGwAAEFIINwAAIKQQbgAAQEgh3AAAgJDy/wHgxjR6v27q3AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract the training and testing loss values from the history\n",
        "train_loss = history.history['loss']\n",
        "#val_loss = history.history['val_loss']\n",
        "\n",
        "# Plot the training and validation loss\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "plt.plot(epochs, train_loss, 'b', label='Training Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iMlYAFQk56Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-96ozNpE3-JV",
        "outputId": "1b6f70bd-4c73-4f55-ebfc-19081fb0ec52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save('rnn_model2_epochs600_batch16.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5oOSswS3-JV",
        "outputId": "17989cc1-555b-41c0-eeb0-4f013d08dba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 1s 2ms/step - loss: 1.0344 - accuracy: 0.6450\n",
            "Test accuracy: 0.6449999809265137\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on test data\n",
        "test_loss, test_acc = model.evaluate(X_test_reshaped, y_test_encoded)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=128, input_shape=(num_timesteps, X_train_reshaped.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))  # Adding dropout for regularization\n",
        "\n",
        "model.add(LSTM(units=64, return_sequences=True))\n",
        "model.add(Dropout(0.2))  # Adding dropout for regularization\n",
        "\n",
        "model.add(LSTM(units=32))  # Last LSTM layer without return_sequences\n",
        "model.add(Dropout(0.2))  # Adding dropout for regularization\n",
        "\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dense(units=len(labels.unique()), activation='softmax'))  # Adjust the output units based on the number of classes\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_reshaped, y_train_encoded, epochs=600, batch_size=32, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3HF4HbT6b8P",
        "outputId": "519b6552-53aa-4834-c159-513c98ef08c4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "23/23 [==============================] - 9s 82ms/step - loss: 2.2894 - accuracy: 0.2722 - val_loss: 2.2606 - val_accuracy: 0.3375\n",
            "Epoch 2/600\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 2.1858 - accuracy: 0.3597 - val_loss: 2.0447 - val_accuracy: 0.3125\n",
            "Epoch 3/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 1.9592 - accuracy: 0.3611 - val_loss: 1.8287 - val_accuracy: 0.3500\n",
            "Epoch 4/600\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 1.7372 - accuracy: 0.3931 - val_loss: 1.6180 - val_accuracy: 0.4000\n",
            "Epoch 5/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 1.5350 - accuracy: 0.4236 - val_loss: 1.4376 - val_accuracy: 0.4500\n",
            "Epoch 6/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 1.3871 - accuracy: 0.4597 - val_loss: 1.3081 - val_accuracy: 0.5000\n",
            "Epoch 7/600\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 1.2734 - accuracy: 0.5236 - val_loss: 1.2160 - val_accuracy: 0.5375\n",
            "Epoch 8/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 1.1848 - accuracy: 0.5333 - val_loss: 1.1423 - val_accuracy: 0.6000\n",
            "Epoch 9/600\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 1.0758 - accuracy: 0.5889 - val_loss: 1.1048 - val_accuracy: 0.5375\n",
            "Epoch 10/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 1.0154 - accuracy: 0.6347 - val_loss: 1.1103 - val_accuracy: 0.5500\n",
            "Epoch 11/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.9419 - accuracy: 0.6500 - val_loss: 1.0297 - val_accuracy: 0.6000\n",
            "Epoch 12/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.8924 - accuracy: 0.6583 - val_loss: 1.0575 - val_accuracy: 0.5625\n",
            "Epoch 13/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.8438 - accuracy: 0.6986 - val_loss: 1.0279 - val_accuracy: 0.5875\n",
            "Epoch 14/600\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.7763 - accuracy: 0.7222 - val_loss: 1.0139 - val_accuracy: 0.6375\n",
            "Epoch 15/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.7224 - accuracy: 0.7653 - val_loss: 0.9555 - val_accuracy: 0.6875\n",
            "Epoch 16/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.6660 - accuracy: 0.7778 - val_loss: 1.0965 - val_accuracy: 0.5750\n",
            "Epoch 17/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - accuracy: 0.7667 - val_loss: 1.0230 - val_accuracy: 0.6375\n",
            "Epoch 18/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.6099 - accuracy: 0.8028 - val_loss: 1.0539 - val_accuracy: 0.6125\n",
            "Epoch 19/600\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.5490 - accuracy: 0.8028 - val_loss: 1.0097 - val_accuracy: 0.6375\n",
            "Epoch 20/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.5145 - accuracy: 0.8306 - val_loss: 1.0933 - val_accuracy: 0.6250\n",
            "Epoch 21/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.4924 - accuracy: 0.8347 - val_loss: 1.0306 - val_accuracy: 0.7000\n",
            "Epoch 22/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.4391 - accuracy: 0.8486 - val_loss: 1.0742 - val_accuracy: 0.6250\n",
            "Epoch 23/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.4432 - accuracy: 0.8569 - val_loss: 1.0184 - val_accuracy: 0.6375\n",
            "Epoch 24/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.4124 - accuracy: 0.8694 - val_loss: 1.0776 - val_accuracy: 0.6250\n",
            "Epoch 25/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.3925 - accuracy: 0.8583 - val_loss: 1.0908 - val_accuracy: 0.6750\n",
            "Epoch 26/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3816 - accuracy: 0.8681 - val_loss: 1.1393 - val_accuracy: 0.6625\n",
            "Epoch 27/600\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.2990 - accuracy: 0.8917 - val_loss: 1.0824 - val_accuracy: 0.6750\n",
            "Epoch 28/600\n",
            "23/23 [==============================] - 1s 30ms/step - loss: 0.2882 - accuracy: 0.8986 - val_loss: 1.2329 - val_accuracy: 0.6750\n",
            "Epoch 29/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.3330 - accuracy: 0.8792 - val_loss: 1.2641 - val_accuracy: 0.6375\n",
            "Epoch 30/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2841 - accuracy: 0.8986 - val_loss: 1.1572 - val_accuracy: 0.7000\n",
            "Epoch 31/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.2607 - accuracy: 0.9139 - val_loss: 1.3233 - val_accuracy: 0.7125\n",
            "Epoch 32/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2461 - accuracy: 0.9208 - val_loss: 1.2802 - val_accuracy: 0.6875\n",
            "Epoch 33/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2332 - accuracy: 0.9194 - val_loss: 1.3570 - val_accuracy: 0.6875\n",
            "Epoch 34/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2087 - accuracy: 0.9319 - val_loss: 1.2691 - val_accuracy: 0.7000\n",
            "Epoch 35/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2362 - accuracy: 0.9236 - val_loss: 1.4239 - val_accuracy: 0.7250\n",
            "Epoch 36/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.2187 - accuracy: 0.9278 - val_loss: 1.4497 - val_accuracy: 0.6875\n",
            "Epoch 37/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.2011 - accuracy: 0.9417 - val_loss: 1.3153 - val_accuracy: 0.7500\n",
            "Epoch 38/600\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.1709 - accuracy: 0.9444 - val_loss: 1.3278 - val_accuracy: 0.7875\n",
            "Epoch 39/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.1505 - accuracy: 0.9528 - val_loss: 1.3707 - val_accuracy: 0.7500\n",
            "Epoch 40/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.1652 - accuracy: 0.9444 - val_loss: 1.4608 - val_accuracy: 0.7375\n",
            "Epoch 41/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.1500 - accuracy: 0.9417 - val_loss: 1.6449 - val_accuracy: 0.7000\n",
            "Epoch 42/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.1264 - accuracy: 0.9597 - val_loss: 1.5282 - val_accuracy: 0.7125\n",
            "Epoch 43/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.1332 - accuracy: 0.9653 - val_loss: 1.6708 - val_accuracy: 0.7125\n",
            "Epoch 44/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.1174 - accuracy: 0.9667 - val_loss: 1.6335 - val_accuracy: 0.7125\n",
            "Epoch 45/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.1141 - accuracy: 0.9625 - val_loss: 1.5162 - val_accuracy: 0.7250\n",
            "Epoch 46/600\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.1459 - accuracy: 0.9528 - val_loss: 1.6860 - val_accuracy: 0.7250\n",
            "Epoch 47/600\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.1527 - accuracy: 0.9514 - val_loss: 1.6474 - val_accuracy: 0.7000\n",
            "Epoch 48/600\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.1254 - accuracy: 0.9597 - val_loss: 1.5165 - val_accuracy: 0.7250\n",
            "Epoch 49/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.1132 - accuracy: 0.9639 - val_loss: 1.7202 - val_accuracy: 0.7000\n",
            "Epoch 50/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.1314 - accuracy: 0.9653 - val_loss: 1.7140 - val_accuracy: 0.7125\n",
            "Epoch 51/600\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.1145 - accuracy: 0.9639 - val_loss: 1.7613 - val_accuracy: 0.6750\n",
            "Epoch 52/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0901 - accuracy: 0.9778 - val_loss: 1.7822 - val_accuracy: 0.7375\n",
            "Epoch 53/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.1257 - accuracy: 0.9583 - val_loss: 1.7414 - val_accuracy: 0.7250\n",
            "Epoch 54/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.1140 - accuracy: 0.9639 - val_loss: 1.6738 - val_accuracy: 0.7250\n",
            "Epoch 55/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.1160 - accuracy: 0.9625 - val_loss: 1.6184 - val_accuracy: 0.7250\n",
            "Epoch 56/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.1168 - accuracy: 0.9611 - val_loss: 1.7180 - val_accuracy: 0.7125\n",
            "Epoch 57/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0990 - accuracy: 0.9667 - val_loss: 1.6653 - val_accuracy: 0.7500\n",
            "Epoch 58/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.1140 - accuracy: 0.9653 - val_loss: 1.8267 - val_accuracy: 0.7250\n",
            "Epoch 59/600\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0884 - accuracy: 0.9708 - val_loss: 1.7630 - val_accuracy: 0.7375\n",
            "Epoch 60/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0814 - accuracy: 0.9778 - val_loss: 1.6770 - val_accuracy: 0.7375\n",
            "Epoch 61/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0711 - accuracy: 0.9792 - val_loss: 1.8137 - val_accuracy: 0.7375\n",
            "Epoch 62/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0697 - accuracy: 0.9806 - val_loss: 1.7595 - val_accuracy: 0.7125\n",
            "Epoch 63/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0501 - accuracy: 0.9889 - val_loss: 1.7754 - val_accuracy: 0.7375\n",
            "Epoch 64/600\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0817 - accuracy: 0.9792 - val_loss: 1.7943 - val_accuracy: 0.7250\n",
            "Epoch 65/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0564 - accuracy: 0.9819 - val_loss: 1.7728 - val_accuracy: 0.7250\n",
            "Epoch 66/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0661 - accuracy: 0.9819 - val_loss: 2.0244 - val_accuracy: 0.7125\n",
            "Epoch 67/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0697 - accuracy: 0.9764 - val_loss: 1.9272 - val_accuracy: 0.7250\n",
            "Epoch 68/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0619 - accuracy: 0.9778 - val_loss: 1.9525 - val_accuracy: 0.6875\n",
            "Epoch 69/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0669 - accuracy: 0.9819 - val_loss: 1.8629 - val_accuracy: 0.7375\n",
            "Epoch 70/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0656 - accuracy: 0.9792 - val_loss: 1.8510 - val_accuracy: 0.7250\n",
            "Epoch 71/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0622 - accuracy: 0.9806 - val_loss: 2.0251 - val_accuracy: 0.7250\n",
            "Epoch 72/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0613 - accuracy: 0.9806 - val_loss: 1.9731 - val_accuracy: 0.7125\n",
            "Epoch 73/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0700 - accuracy: 0.9708 - val_loss: 1.9937 - val_accuracy: 0.7375\n",
            "Epoch 74/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0753 - accuracy: 0.9722 - val_loss: 2.0117 - val_accuracy: 0.7125\n",
            "Epoch 75/600\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0535 - accuracy: 0.9847 - val_loss: 2.1599 - val_accuracy: 0.7000\n",
            "Epoch 76/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0611 - accuracy: 0.9833 - val_loss: 2.1399 - val_accuracy: 0.7000\n",
            "Epoch 77/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0587 - accuracy: 0.9861 - val_loss: 1.8887 - val_accuracy: 0.7375\n",
            "Epoch 78/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0720 - accuracy: 0.9736 - val_loss: 1.8624 - val_accuracy: 0.7125\n",
            "Epoch 79/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0777 - accuracy: 0.9625 - val_loss: 2.0805 - val_accuracy: 0.7125\n",
            "Epoch 80/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0671 - accuracy: 0.9764 - val_loss: 2.0068 - val_accuracy: 0.6875\n",
            "Epoch 81/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0534 - accuracy: 0.9819 - val_loss: 1.9257 - val_accuracy: 0.7250\n",
            "Epoch 82/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0362 - accuracy: 0.9917 - val_loss: 2.0161 - val_accuracy: 0.7125\n",
            "Epoch 83/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0424 - accuracy: 0.9917 - val_loss: 2.0483 - val_accuracy: 0.7375\n",
            "Epoch 84/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0565 - accuracy: 0.9833 - val_loss: 1.8203 - val_accuracy: 0.7750\n",
            "Epoch 85/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0472 - accuracy: 0.9833 - val_loss: 2.0801 - val_accuracy: 0.7000\n",
            "Epoch 86/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0566 - accuracy: 0.9819 - val_loss: 1.9954 - val_accuracy: 0.7125\n",
            "Epoch 87/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0386 - accuracy: 0.9875 - val_loss: 2.2489 - val_accuracy: 0.6875\n",
            "Epoch 88/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0449 - accuracy: 0.9861 - val_loss: 2.1174 - val_accuracy: 0.7250\n",
            "Epoch 89/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0201 - accuracy: 0.9944 - val_loss: 2.0810 - val_accuracy: 0.7250\n",
            "Epoch 90/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0521 - accuracy: 0.9833 - val_loss: 2.1972 - val_accuracy: 0.6875\n",
            "Epoch 91/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0457 - accuracy: 0.9833 - val_loss: 1.9811 - val_accuracy: 0.7250\n",
            "Epoch 92/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0434 - accuracy: 0.9819 - val_loss: 2.2979 - val_accuracy: 0.6875\n",
            "Epoch 93/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0447 - accuracy: 0.9861 - val_loss: 2.1464 - val_accuracy: 0.6750\n",
            "Epoch 94/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0467 - accuracy: 0.9806 - val_loss: 2.0299 - val_accuracy: 0.6875\n",
            "Epoch 95/600\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0430 - accuracy: 0.9819 - val_loss: 1.9720 - val_accuracy: 0.7125\n",
            "Epoch 96/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0473 - accuracy: 0.9847 - val_loss: 1.9807 - val_accuracy: 0.7125\n",
            "Epoch 97/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0392 - accuracy: 0.9889 - val_loss: 1.9988 - val_accuracy: 0.7500\n",
            "Epoch 98/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0361 - accuracy: 0.9903 - val_loss: 2.1454 - val_accuracy: 0.6750\n",
            "Epoch 99/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0439 - accuracy: 0.9819 - val_loss: 2.0518 - val_accuracy: 0.7250\n",
            "Epoch 100/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0550 - accuracy: 0.9819 - val_loss: 2.0036 - val_accuracy: 0.7625\n",
            "Epoch 101/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0509 - accuracy: 0.9819 - val_loss: 2.0572 - val_accuracy: 0.7125\n",
            "Epoch 102/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0429 - accuracy: 0.9875 - val_loss: 1.9742 - val_accuracy: 0.7125\n",
            "Epoch 103/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0501 - accuracy: 0.9861 - val_loss: 1.9523 - val_accuracy: 0.7375\n",
            "Epoch 104/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0387 - accuracy: 0.9903 - val_loss: 2.0674 - val_accuracy: 0.7375\n",
            "Epoch 105/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0408 - accuracy: 0.9847 - val_loss: 2.2496 - val_accuracy: 0.7125\n",
            "Epoch 106/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0264 - accuracy: 0.9917 - val_loss: 2.1674 - val_accuracy: 0.7000\n",
            "Epoch 107/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9931 - val_loss: 2.1516 - val_accuracy: 0.7125\n",
            "Epoch 108/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0511 - accuracy: 0.9806 - val_loss: 2.0445 - val_accuracy: 0.7250\n",
            "Epoch 109/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0318 - accuracy: 0.9889 - val_loss: 1.9068 - val_accuracy: 0.7250\n",
            "Epoch 110/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0301 - accuracy: 0.9875 - val_loss: 2.0582 - val_accuracy: 0.7250\n",
            "Epoch 111/600\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0153 - accuracy: 0.9972 - val_loss: 2.2831 - val_accuracy: 0.7000\n",
            "Epoch 112/600\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0279 - accuracy: 0.9903 - val_loss: 2.1668 - val_accuracy: 0.7250\n",
            "Epoch 113/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 0.9958 - val_loss: 2.2440 - val_accuracy: 0.6875\n",
            "Epoch 114/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0283 - accuracy: 0.9917 - val_loss: 2.2278 - val_accuracy: 0.7250\n",
            "Epoch 115/600\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0321 - accuracy: 0.9875 - val_loss: 2.0951 - val_accuracy: 0.7625\n",
            "Epoch 116/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0346 - accuracy: 0.9903 - val_loss: 2.0079 - val_accuracy: 0.7625\n",
            "Epoch 117/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0145 - accuracy: 0.9958 - val_loss: 1.9671 - val_accuracy: 0.7625\n",
            "Epoch 118/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0258 - accuracy: 0.9917 - val_loss: 2.0323 - val_accuracy: 0.7625\n",
            "Epoch 119/600\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0201 - accuracy: 0.9958 - val_loss: 2.0711 - val_accuracy: 0.7625\n",
            "Epoch 120/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9903 - val_loss: 2.0720 - val_accuracy: 0.7750\n",
            "Epoch 121/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0237 - accuracy: 0.9875 - val_loss: 2.1772 - val_accuracy: 0.7375\n",
            "Epoch 122/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0207 - accuracy: 0.9903 - val_loss: 2.2217 - val_accuracy: 0.7125\n",
            "Epoch 123/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0209 - accuracy: 0.9944 - val_loss: 2.2347 - val_accuracy: 0.7500\n",
            "Epoch 124/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0269 - accuracy: 0.9903 - val_loss: 2.2916 - val_accuracy: 0.7625\n",
            "Epoch 125/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0478 - accuracy: 0.9875 - val_loss: 2.1829 - val_accuracy: 0.7250\n",
            "Epoch 126/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0157 - accuracy: 0.9944 - val_loss: 2.0321 - val_accuracy: 0.7250\n",
            "Epoch 127/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0285 - accuracy: 0.9944 - val_loss: 2.0258 - val_accuracy: 0.7250\n",
            "Epoch 128/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0257 - accuracy: 0.9931 - val_loss: 2.1482 - val_accuracy: 0.7375\n",
            "Epoch 129/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0238 - accuracy: 0.9889 - val_loss: 2.0193 - val_accuracy: 0.7625\n",
            "Epoch 130/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0164 - accuracy: 0.9931 - val_loss: 2.0467 - val_accuracy: 0.7875\n",
            "Epoch 131/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0275 - accuracy: 0.9917 - val_loss: 2.1802 - val_accuracy: 0.7625\n",
            "Epoch 132/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9917 - val_loss: 2.1877 - val_accuracy: 0.7500\n",
            "Epoch 133/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0189 - accuracy: 0.9944 - val_loss: 2.2130 - val_accuracy: 0.7375\n",
            "Epoch 134/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0165 - accuracy: 0.9958 - val_loss: 2.3403 - val_accuracy: 0.7125\n",
            "Epoch 135/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0217 - accuracy: 0.9903 - val_loss: 2.2144 - val_accuracy: 0.7250\n",
            "Epoch 136/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0268 - accuracy: 0.9917 - val_loss: 2.2285 - val_accuracy: 0.7375\n",
            "Epoch 137/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0277 - accuracy: 0.9847 - val_loss: 2.2597 - val_accuracy: 0.7500\n",
            "Epoch 138/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 2.1763 - val_accuracy: 0.7500\n",
            "Epoch 139/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0225 - accuracy: 0.9931 - val_loss: 2.2425 - val_accuracy: 0.7375\n",
            "Epoch 140/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0338 - accuracy: 0.9903 - val_loss: 2.3418 - val_accuracy: 0.7375\n",
            "Epoch 141/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0475 - accuracy: 0.9889 - val_loss: 2.3979 - val_accuracy: 0.7375\n",
            "Epoch 142/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0305 - accuracy: 0.9903 - val_loss: 2.4072 - val_accuracy: 0.7125\n",
            "Epoch 143/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0567 - accuracy: 0.9806 - val_loss: 2.3762 - val_accuracy: 0.7375\n",
            "Epoch 144/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0690 - accuracy: 0.9806 - val_loss: 2.2025 - val_accuracy: 0.7500\n",
            "Epoch 145/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0350 - accuracy: 0.9889 - val_loss: 2.1920 - val_accuracy: 0.7250\n",
            "Epoch 146/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0302 - accuracy: 0.9903 - val_loss: 2.0822 - val_accuracy: 0.7375\n",
            "Epoch 147/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0196 - accuracy: 0.9931 - val_loss: 2.2111 - val_accuracy: 0.7375\n",
            "Epoch 148/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0304 - accuracy: 0.9903 - val_loss: 2.4168 - val_accuracy: 0.6750\n",
            "Epoch 149/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0455 - accuracy: 0.9861 - val_loss: 2.2853 - val_accuracy: 0.7375\n",
            "Epoch 150/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0221 - accuracy: 0.9903 - val_loss: 2.1182 - val_accuracy: 0.7500\n",
            "Epoch 151/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0173 - accuracy: 0.9958 - val_loss: 2.2498 - val_accuracy: 0.7000\n",
            "Epoch 152/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0215 - accuracy: 0.9931 - val_loss: 2.3105 - val_accuracy: 0.7000\n",
            "Epoch 153/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0276 - accuracy: 0.9917 - val_loss: 2.2986 - val_accuracy: 0.7250\n",
            "Epoch 154/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 0.9972 - val_loss: 2.3322 - val_accuracy: 0.7000\n",
            "Epoch 155/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0264 - accuracy: 0.9944 - val_loss: 2.1211 - val_accuracy: 0.7125\n",
            "Epoch 156/600\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0431 - accuracy: 0.9875 - val_loss: 2.1472 - val_accuracy: 0.7500\n",
            "Epoch 157/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0141 - accuracy: 0.9944 - val_loss: 2.0450 - val_accuracy: 0.7375\n",
            "Epoch 158/600\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0149 - accuracy: 0.9958 - val_loss: 2.1212 - val_accuracy: 0.7125\n",
            "Epoch 159/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0243 - accuracy: 0.9931 - val_loss: 2.3774 - val_accuracy: 0.7375\n",
            "Epoch 160/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0171 - accuracy: 0.9931 - val_loss: 2.3895 - val_accuracy: 0.7250\n",
            "Epoch 161/600\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0254 - accuracy: 0.9917 - val_loss: 2.3544 - val_accuracy: 0.7500\n",
            "Epoch 162/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 2.4043 - val_accuracy: 0.7375\n",
            "Epoch 163/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0193 - accuracy: 0.9944 - val_loss: 2.3782 - val_accuracy: 0.7375\n",
            "Epoch 164/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.4110 - val_accuracy: 0.7375\n",
            "Epoch 165/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0188 - accuracy: 0.9944 - val_loss: 2.3874 - val_accuracy: 0.7250\n",
            "Epoch 166/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0195 - accuracy: 0.9944 - val_loss: 2.1167 - val_accuracy: 0.7625\n",
            "Epoch 167/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0082 - accuracy: 0.9986 - val_loss: 2.0516 - val_accuracy: 0.7875\n",
            "Epoch 168/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0140 - accuracy: 0.9986 - val_loss: 2.0996 - val_accuracy: 0.7250\n",
            "Epoch 169/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0116 - accuracy: 0.9972 - val_loss: 2.1645 - val_accuracy: 0.7375\n",
            "Epoch 170/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0261 - accuracy: 0.9875 - val_loss: 2.4085 - val_accuracy: 0.7125\n",
            "Epoch 171/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0162 - accuracy: 0.9944 - val_loss: 2.7723 - val_accuracy: 0.6750\n",
            "Epoch 172/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0340 - accuracy: 0.9903 - val_loss: 2.5568 - val_accuracy: 0.7250\n",
            "Epoch 173/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 2.4705 - val_accuracy: 0.7250\n",
            "Epoch 174/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 2.0933 - val_accuracy: 0.7625\n",
            "Epoch 175/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0106 - accuracy: 0.9958 - val_loss: 2.2284 - val_accuracy: 0.7250\n",
            "Epoch 176/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0150 - accuracy: 0.9931 - val_loss: 2.1448 - val_accuracy: 0.7375\n",
            "Epoch 177/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0253 - accuracy: 0.9944 - val_loss: 2.4264 - val_accuracy: 0.7000\n",
            "Epoch 178/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 2.1566 - val_accuracy: 0.7500\n",
            "Epoch 179/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0157 - accuracy: 0.9931 - val_loss: 2.2843 - val_accuracy: 0.7125\n",
            "Epoch 180/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0189 - accuracy: 0.9944 - val_loss: 2.2703 - val_accuracy: 0.7125\n",
            "Epoch 181/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0137 - accuracy: 0.9972 - val_loss: 2.3096 - val_accuracy: 0.7125\n",
            "Epoch 182/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 0.9875 - val_loss: 2.3094 - val_accuracy: 0.7125\n",
            "Epoch 183/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0291 - accuracy: 0.9847 - val_loss: 2.2049 - val_accuracy: 0.7500\n",
            "Epoch 184/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9931 - val_loss: 2.4325 - val_accuracy: 0.7375\n",
            "Epoch 185/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0078 - accuracy: 0.9986 - val_loss: 2.3679 - val_accuracy: 0.7250\n",
            "Epoch 186/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0129 - accuracy: 0.9944 - val_loss: 2.3258 - val_accuracy: 0.7375\n",
            "Epoch 187/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 0.9944 - val_loss: 2.5140 - val_accuracy: 0.7125\n",
            "Epoch 188/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 2.3776 - val_accuracy: 0.7375\n",
            "Epoch 189/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0159 - accuracy: 0.9917 - val_loss: 2.5754 - val_accuracy: 0.7250\n",
            "Epoch 190/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0184 - accuracy: 0.9917 - val_loss: 2.6519 - val_accuracy: 0.7250\n",
            "Epoch 191/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0217 - accuracy: 0.9931 - val_loss: 2.6025 - val_accuracy: 0.7250\n",
            "Epoch 192/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0105 - accuracy: 0.9972 - val_loss: 2.5743 - val_accuracy: 0.7125\n",
            "Epoch 193/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 2.4245 - val_accuracy: 0.7375\n",
            "Epoch 194/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0150 - accuracy: 0.9958 - val_loss: 2.4887 - val_accuracy: 0.7500\n",
            "Epoch 195/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0193 - accuracy: 0.9931 - val_loss: 2.7854 - val_accuracy: 0.7125\n",
            "Epoch 196/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 2.6975 - val_accuracy: 0.7500\n",
            "Epoch 197/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0134 - accuracy: 0.9931 - val_loss: 2.6472 - val_accuracy: 0.7500\n",
            "Epoch 198/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0214 - accuracy: 0.9889 - val_loss: 2.7223 - val_accuracy: 0.7750\n",
            "Epoch 199/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 2.7211 - val_accuracy: 0.7750\n",
            "Epoch 200/600\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 2.7434 - val_accuracy: 0.7625\n",
            "Epoch 201/600\n",
            "23/23 [==============================] - 0s 20ms/step - loss: 0.0127 - accuracy: 0.9972 - val_loss: 2.6374 - val_accuracy: 0.7500\n",
            "Epoch 202/600\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.0112 - accuracy: 0.9958 - val_loss: 2.5786 - val_accuracy: 0.6875\n",
            "Epoch 203/600\n",
            "23/23 [==============================] - 1s 33ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 2.7224 - val_accuracy: 0.7500\n",
            "Epoch 204/600\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.0113 - accuracy: 0.9944 - val_loss: 2.8038 - val_accuracy: 0.6875\n",
            "Epoch 205/600\n",
            "23/23 [==============================] - 1s 28ms/step - loss: 0.0235 - accuracy: 0.9917 - val_loss: 2.6896 - val_accuracy: 0.7625\n",
            "Epoch 206/600\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.0187 - accuracy: 0.9944 - val_loss: 2.8575 - val_accuracy: 0.7125\n",
            "Epoch 207/600\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 2.8104 - val_accuracy: 0.6750\n",
            "Epoch 208/600\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 2.7390 - val_accuracy: 0.6750\n",
            "Epoch 209/600\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 2.6333 - val_accuracy: 0.7375\n",
            "Epoch 210/600\n",
            "23/23 [==============================] - 1s 34ms/step - loss: 0.0241 - accuracy: 0.9903 - val_loss: 2.7672 - val_accuracy: 0.7500\n",
            "Epoch 211/600\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.0106 - accuracy: 0.9986 - val_loss: 2.6572 - val_accuracy: 0.7375\n",
            "Epoch 212/600\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 2.5103 - val_accuracy: 0.7375\n",
            "Epoch 213/600\n",
            "23/23 [==============================] - 0s 21ms/step - loss: 0.0095 - accuracy: 0.9958 - val_loss: 2.3949 - val_accuracy: 0.7125\n",
            "Epoch 214/600\n",
            "23/23 [==============================] - 0s 22ms/step - loss: 0.0209 - accuracy: 0.9903 - val_loss: 2.3783 - val_accuracy: 0.7625\n",
            "Epoch 215/600\n",
            "23/23 [==============================] - 1s 22ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 2.4284 - val_accuracy: 0.7375\n",
            "Epoch 216/600\n",
            "23/23 [==============================] - 1s 22ms/step - loss: 0.0165 - accuracy: 0.9931 - val_loss: 2.4018 - val_accuracy: 0.7375\n",
            "Epoch 217/600\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.0080 - accuracy: 0.9986 - val_loss: 2.3720 - val_accuracy: 0.7500\n",
            "Epoch 218/600\n",
            "23/23 [==============================] - 0s 21ms/step - loss: 0.0197 - accuracy: 0.9944 - val_loss: 2.4295 - val_accuracy: 0.7625\n",
            "Epoch 219/600\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.0089 - accuracy: 0.9958 - val_loss: 2.5432 - val_accuracy: 0.7250\n",
            "Epoch 220/600\n",
            "23/23 [==============================] - 0s 20ms/step - loss: 0.0174 - accuracy: 0.9958 - val_loss: 2.5517 - val_accuracy: 0.7375\n",
            "Epoch 221/600\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.0242 - accuracy: 0.9903 - val_loss: 2.8533 - val_accuracy: 0.6875\n",
            "Epoch 222/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0112 - accuracy: 0.9958 - val_loss: 2.4817 - val_accuracy: 0.7375\n",
            "Epoch 223/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0236 - accuracy: 0.9944 - val_loss: 2.4208 - val_accuracy: 0.7375\n",
            "Epoch 224/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0190 - accuracy: 0.9944 - val_loss: 2.3412 - val_accuracy: 0.7250\n",
            "Epoch 225/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0108 - accuracy: 0.9972 - val_loss: 2.4827 - val_accuracy: 0.7000\n",
            "Epoch 226/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.5552 - val_accuracy: 0.6750\n",
            "Epoch 227/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0124 - accuracy: 0.9972 - val_loss: 2.8446 - val_accuracy: 0.6625\n",
            "Epoch 228/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0152 - accuracy: 0.9944 - val_loss: 2.6665 - val_accuracy: 0.6875\n",
            "Epoch 229/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0105 - accuracy: 0.9972 - val_loss: 2.5732 - val_accuracy: 0.7375\n",
            "Epoch 230/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0183 - accuracy: 0.9944 - val_loss: 2.6767 - val_accuracy: 0.7000\n",
            "Epoch 231/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0148 - accuracy: 0.9944 - val_loss: 2.7353 - val_accuracy: 0.6625\n",
            "Epoch 232/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0160 - accuracy: 0.9958 - val_loss: 2.5926 - val_accuracy: 0.7125\n",
            "Epoch 233/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0076 - accuracy: 0.9986 - val_loss: 2.8953 - val_accuracy: 0.6750\n",
            "Epoch 234/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0131 - accuracy: 0.9931 - val_loss: 2.6664 - val_accuracy: 0.7500\n",
            "Epoch 235/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0102 - accuracy: 0.9958 - val_loss: 2.6910 - val_accuracy: 0.7250\n",
            "Epoch 236/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0486 - accuracy: 0.9875 - val_loss: 2.7017 - val_accuracy: 0.7125\n",
            "Epoch 237/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0553 - accuracy: 0.9889 - val_loss: 2.7724 - val_accuracy: 0.7000\n",
            "Epoch 238/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 2.8410 - val_accuracy: 0.7000\n",
            "Epoch 239/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 2.7473 - val_accuracy: 0.7125\n",
            "Epoch 240/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0308 - accuracy: 0.9917 - val_loss: 2.8892 - val_accuracy: 0.7125\n",
            "Epoch 241/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 2.9974 - val_accuracy: 0.7125\n",
            "Epoch 242/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0414 - accuracy: 0.9903 - val_loss: 2.6336 - val_accuracy: 0.7125\n",
            "Epoch 243/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0211 - accuracy: 0.9944 - val_loss: 2.7537 - val_accuracy: 0.7125\n",
            "Epoch 244/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0102 - accuracy: 0.9944 - val_loss: 2.9162 - val_accuracy: 0.7000\n",
            "Epoch 245/600\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0130 - accuracy: 0.9986 - val_loss: 2.9748 - val_accuracy: 0.6875\n",
            "Epoch 246/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0146 - accuracy: 0.9931 - val_loss: 2.8787 - val_accuracy: 0.7250\n",
            "Epoch 247/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 2.8822 - val_accuracy: 0.7125\n",
            "Epoch 248/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0128 - accuracy: 0.9944 - val_loss: 2.8172 - val_accuracy: 0.7125\n",
            "Epoch 249/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0133 - accuracy: 0.9931 - val_loss: 2.8019 - val_accuracy: 0.7250\n",
            "Epoch 250/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.7891 - val_accuracy: 0.7125\n",
            "Epoch 251/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0089 - accuracy: 0.9958 - val_loss: 2.6550 - val_accuracy: 0.7375\n",
            "Epoch 252/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0065 - accuracy: 0.9972 - val_loss: 2.7147 - val_accuracy: 0.7375\n",
            "Epoch 253/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0149 - accuracy: 0.9958 - val_loss: 2.7455 - val_accuracy: 0.7125\n",
            "Epoch 254/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0218 - accuracy: 0.9917 - val_loss: 2.7158 - val_accuracy: 0.7125\n",
            "Epoch 255/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0287 - accuracy: 0.9917 - val_loss: 2.6668 - val_accuracy: 0.7125\n",
            "Epoch 256/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0226 - accuracy: 0.9917 - val_loss: 2.5024 - val_accuracy: 0.7125\n",
            "Epoch 257/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 2.5106 - val_accuracy: 0.7375\n",
            "Epoch 258/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0114 - accuracy: 0.9931 - val_loss: 2.5686 - val_accuracy: 0.7250\n",
            "Epoch 259/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0169 - accuracy: 0.9917 - val_loss: 2.5652 - val_accuracy: 0.7375\n",
            "Epoch 260/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 2.4896 - val_accuracy: 0.7375\n",
            "Epoch 261/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0125 - accuracy: 0.9944 - val_loss: 2.4628 - val_accuracy: 0.7625\n",
            "Epoch 262/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0196 - accuracy: 0.9917 - val_loss: 2.5293 - val_accuracy: 0.7625\n",
            "Epoch 263/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 2.7558 - val_accuracy: 0.7375\n",
            "Epoch 264/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0281 - accuracy: 0.9931 - val_loss: 2.8289 - val_accuracy: 0.7000\n",
            "Epoch 265/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0114 - accuracy: 0.9944 - val_loss: 2.7916 - val_accuracy: 0.7000\n",
            "Epoch 266/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0160 - accuracy: 0.9944 - val_loss: 3.0650 - val_accuracy: 0.6875\n",
            "Epoch 267/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0175 - accuracy: 0.9958 - val_loss: 3.0842 - val_accuracy: 0.6750\n",
            "Epoch 268/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0245 - accuracy: 0.9944 - val_loss: 3.0808 - val_accuracy: 0.6875\n",
            "Epoch 269/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9958 - val_loss: 2.8515 - val_accuracy: 0.7125\n",
            "Epoch 270/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0130 - accuracy: 0.9944 - val_loss: 2.6357 - val_accuracy: 0.7375\n",
            "Epoch 271/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0247 - accuracy: 0.9972 - val_loss: 2.6953 - val_accuracy: 0.7375\n",
            "Epoch 272/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0089 - accuracy: 0.9958 - val_loss: 2.6851 - val_accuracy: 0.7375\n",
            "Epoch 273/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 2.7767 - val_accuracy: 0.7250\n",
            "Epoch 274/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0031 - accuracy: 0.9986 - val_loss: 2.7798 - val_accuracy: 0.7375\n",
            "Epoch 275/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0133 - accuracy: 0.9972 - val_loss: 2.7403 - val_accuracy: 0.7250\n",
            "Epoch 276/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 2.8903 - val_accuracy: 0.7500\n",
            "Epoch 277/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0072 - accuracy: 0.9972 - val_loss: 2.8071 - val_accuracy: 0.7625\n",
            "Epoch 278/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0127 - accuracy: 0.9972 - val_loss: 3.0619 - val_accuracy: 0.7250\n",
            "Epoch 279/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0174 - accuracy: 0.9903 - val_loss: 3.1068 - val_accuracy: 0.7125\n",
            "Epoch 280/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0148 - accuracy: 0.9944 - val_loss: 3.1118 - val_accuracy: 0.7000\n",
            "Epoch 281/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 0.9972 - val_loss: 3.1765 - val_accuracy: 0.6750\n",
            "Epoch 282/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0077 - accuracy: 0.9986 - val_loss: 3.1376 - val_accuracy: 0.7000\n",
            "Epoch 283/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0112 - accuracy: 0.9958 - val_loss: 3.4358 - val_accuracy: 0.6500\n",
            "Epoch 284/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 3.2692 - val_accuracy: 0.6500\n",
            "Epoch 285/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0097 - accuracy: 0.9944 - val_loss: 3.3233 - val_accuracy: 0.6750\n",
            "Epoch 286/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0109 - accuracy: 0.9944 - val_loss: 3.4343 - val_accuracy: 0.6625\n",
            "Epoch 287/600\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0089 - accuracy: 0.9986 - val_loss: 3.3382 - val_accuracy: 0.6375\n",
            "Epoch 288/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 3.1665 - val_accuracy: 0.6625\n",
            "Epoch 289/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.1448 - val_accuracy: 0.6750\n",
            "Epoch 290/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 3.1342 - val_accuracy: 0.6750\n",
            "Epoch 291/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0041 - accuracy: 0.9972 - val_loss: 3.1649 - val_accuracy: 0.6750\n",
            "Epoch 292/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0025 - accuracy: 0.9986 - val_loss: 3.1668 - val_accuracy: 0.6750\n",
            "Epoch 293/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0101 - accuracy: 0.9944 - val_loss: 2.9668 - val_accuracy: 0.7000\n",
            "Epoch 294/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0070 - accuracy: 0.9972 - val_loss: 2.7823 - val_accuracy: 0.7125\n",
            "Epoch 295/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0126 - accuracy: 0.9972 - val_loss: 2.7269 - val_accuracy: 0.7125\n",
            "Epoch 296/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0049 - accuracy: 0.9972 - val_loss: 2.8141 - val_accuracy: 0.7000\n",
            "Epoch 297/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0072 - accuracy: 0.9958 - val_loss: 2.7006 - val_accuracy: 0.7125\n",
            "Epoch 298/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0206 - accuracy: 0.9903 - val_loss: 2.6320 - val_accuracy: 0.7250\n",
            "Epoch 299/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 2.6647 - val_accuracy: 0.7375\n",
            "Epoch 300/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 2.7464 - val_accuracy: 0.7250\n",
            "Epoch 301/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0089 - accuracy: 0.9958 - val_loss: 2.7796 - val_accuracy: 0.7125\n",
            "Epoch 302/600\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.0107 - accuracy: 0.9944 - val_loss: 2.6282 - val_accuracy: 0.6875\n",
            "Epoch 303/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0405 - accuracy: 0.9944 - val_loss: 2.8294 - val_accuracy: 0.7125\n",
            "Epoch 304/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0092 - accuracy: 0.9958 - val_loss: 2.7485 - val_accuracy: 0.6750\n",
            "Epoch 305/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0089 - accuracy: 0.9986 - val_loss: 2.8208 - val_accuracy: 0.7000\n",
            "Epoch 306/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0108 - accuracy: 0.9958 - val_loss: 2.7763 - val_accuracy: 0.7125\n",
            "Epoch 307/600\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 2.8154 - val_accuracy: 0.7000\n",
            "Epoch 308/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0055 - accuracy: 0.9972 - val_loss: 2.7476 - val_accuracy: 0.7000\n",
            "Epoch 309/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 2.8457 - val_accuracy: 0.7000\n",
            "Epoch 310/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 3.0021 - val_accuracy: 0.6750\n",
            "Epoch 311/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 3.0811 - val_accuracy: 0.7125\n",
            "Epoch 312/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0138 - accuracy: 0.9931 - val_loss: 3.2700 - val_accuracy: 0.6875\n",
            "Epoch 313/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0180 - accuracy: 0.9958 - val_loss: 3.2586 - val_accuracy: 0.6500\n",
            "Epoch 314/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 3.0818 - val_accuracy: 0.7000\n",
            "Epoch 315/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 3.2040 - val_accuracy: 0.6750\n",
            "Epoch 316/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0259 - accuracy: 0.9944 - val_loss: 3.0546 - val_accuracy: 0.6750\n",
            "Epoch 317/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0106 - accuracy: 0.9958 - val_loss: 2.9704 - val_accuracy: 0.7000\n",
            "Epoch 318/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.9972 - val_loss: 3.3478 - val_accuracy: 0.6750\n",
            "Epoch 319/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0141 - accuracy: 0.9986 - val_loss: 2.8505 - val_accuracy: 0.7250\n",
            "Epoch 320/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0179 - accuracy: 0.9931 - val_loss: 3.0742 - val_accuracy: 0.6875\n",
            "Epoch 321/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 2.8946 - val_accuracy: 0.7375\n",
            "Epoch 322/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.9502 - val_accuracy: 0.7375\n",
            "Epoch 323/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 0.9972 - val_loss: 2.9500 - val_accuracy: 0.7000\n",
            "Epoch 324/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0088 - accuracy: 0.9958 - val_loss: 3.1077 - val_accuracy: 0.6875\n",
            "Epoch 325/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.9972 - val_loss: 3.2476 - val_accuracy: 0.7125\n",
            "Epoch 326/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0113 - accuracy: 0.9972 - val_loss: 3.0314 - val_accuracy: 0.7000\n",
            "Epoch 327/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0242 - accuracy: 0.9917 - val_loss: 3.2038 - val_accuracy: 0.6750\n",
            "Epoch 328/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0205 - accuracy: 0.9944 - val_loss: 3.1720 - val_accuracy: 0.7000\n",
            "Epoch 329/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0200 - accuracy: 0.9931 - val_loss: 2.9627 - val_accuracy: 0.7250\n",
            "Epoch 330/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0384 - accuracy: 0.9889 - val_loss: 2.6675 - val_accuracy: 0.7250\n",
            "Epoch 331/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 2.9057 - val_accuracy: 0.7000\n",
            "Epoch 332/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0205 - accuracy: 0.9917 - val_loss: 2.6953 - val_accuracy: 0.7000\n",
            "Epoch 333/600\n",
            "23/23 [==============================] - 1s 22ms/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 2.6049 - val_accuracy: 0.7125\n",
            "Epoch 334/600\n",
            "23/23 [==============================] - 0s 21ms/step - loss: 0.0032 - accuracy: 0.9986 - val_loss: 2.6468 - val_accuracy: 0.7000\n",
            "Epoch 335/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 2.5975 - val_accuracy: 0.7000\n",
            "Epoch 336/600\n",
            "23/23 [==============================] - 0s 21ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 2.6162 - val_accuracy: 0.7125\n",
            "Epoch 337/600\n",
            "23/23 [==============================] - 0s 20ms/step - loss: 0.0051 - accuracy: 0.9972 - val_loss: 2.6696 - val_accuracy: 0.6875\n",
            "Epoch 338/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0185 - accuracy: 0.9917 - val_loss: 2.9511 - val_accuracy: 0.7250\n",
            "Epoch 339/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0379 - accuracy: 0.9903 - val_loss: 2.8777 - val_accuracy: 0.7000\n",
            "Epoch 340/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0150 - accuracy: 0.9931 - val_loss: 2.8390 - val_accuracy: 0.7000\n",
            "Epoch 341/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0120 - accuracy: 0.9944 - val_loss: 2.8313 - val_accuracy: 0.6875\n",
            "Epoch 342/600\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0219 - accuracy: 0.9944 - val_loss: 2.9830 - val_accuracy: 0.6875\n",
            "Epoch 343/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0166 - accuracy: 0.9917 - val_loss: 2.9291 - val_accuracy: 0.7250\n",
            "Epoch 344/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0236 - accuracy: 0.9931 - val_loss: 3.0914 - val_accuracy: 0.7000\n",
            "Epoch 345/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0176 - accuracy: 0.9958 - val_loss: 2.8010 - val_accuracy: 0.7000\n",
            "Epoch 346/600\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0187 - accuracy: 0.9972 - val_loss: 2.7336 - val_accuracy: 0.7125\n",
            "Epoch 347/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0391 - accuracy: 0.9889 - val_loss: 2.6744 - val_accuracy: 0.7125\n",
            "Epoch 348/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0272 - accuracy: 0.9903 - val_loss: 2.6901 - val_accuracy: 0.7250\n",
            "Epoch 349/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0409 - accuracy: 0.9861 - val_loss: 2.8839 - val_accuracy: 0.7125\n",
            "Epoch 350/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0208 - accuracy: 0.9944 - val_loss: 2.8501 - val_accuracy: 0.6875\n",
            "Epoch 351/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0071 - accuracy: 0.9958 - val_loss: 2.7366 - val_accuracy: 0.6750\n",
            "Epoch 352/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0329 - accuracy: 0.9889 - val_loss: 2.7135 - val_accuracy: 0.6875\n",
            "Epoch 353/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0090 - accuracy: 0.9958 - val_loss: 2.7828 - val_accuracy: 0.6875\n",
            "Epoch 354/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 2.8083 - val_accuracy: 0.6875\n",
            "Epoch 355/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0122 - accuracy: 0.9944 - val_loss: 2.7314 - val_accuracy: 0.7000\n",
            "Epoch 356/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0120 - accuracy: 0.9931 - val_loss: 2.6846 - val_accuracy: 0.7125\n",
            "Epoch 357/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0098 - accuracy: 0.9958 - val_loss: 2.0596 - val_accuracy: 0.7375\n",
            "Epoch 358/600\n",
            "23/23 [==============================] - 0s 20ms/step - loss: 0.0090 - accuracy: 0.9986 - val_loss: 2.0681 - val_accuracy: 0.7500\n",
            "Epoch 359/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0119 - accuracy: 0.9972 - val_loss: 2.0909 - val_accuracy: 0.7500\n",
            "Epoch 360/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0088 - accuracy: 0.9958 - val_loss: 2.4861 - val_accuracy: 0.7125\n",
            "Epoch 361/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 2.4327 - val_accuracy: 0.7375\n",
            "Epoch 362/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0061 - accuracy: 0.9972 - val_loss: 2.3958 - val_accuracy: 0.7375\n",
            "Epoch 363/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0081 - accuracy: 0.9958 - val_loss: 2.4052 - val_accuracy: 0.7375\n",
            "Epoch 364/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0074 - accuracy: 0.9972 - val_loss: 2.5133 - val_accuracy: 0.7125\n",
            "Epoch 365/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 2.5592 - val_accuracy: 0.7250\n",
            "Epoch 366/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0099 - accuracy: 0.9958 - val_loss: 2.5483 - val_accuracy: 0.7375\n",
            "Epoch 367/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 2.5698 - val_accuracy: 0.7375\n",
            "Epoch 368/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.5529 - val_accuracy: 0.7375\n",
            "Epoch 369/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 2.5534 - val_accuracy: 0.7250\n",
            "Epoch 370/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 2.6217 - val_accuracy: 0.7375\n",
            "Epoch 371/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 2.5872 - val_accuracy: 0.7250\n",
            "Epoch 372/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0096 - accuracy: 0.9958 - val_loss: 2.6974 - val_accuracy: 0.7125\n",
            "Epoch 373/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0102 - accuracy: 0.9958 - val_loss: 2.6776 - val_accuracy: 0.7125\n",
            "Epoch 374/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 0.9972 - val_loss: 2.7152 - val_accuracy: 0.6875\n",
            "Epoch 375/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9958 - val_loss: 2.6574 - val_accuracy: 0.7125\n",
            "Epoch 376/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.6186 - val_accuracy: 0.7125\n",
            "Epoch 377/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0070 - accuracy: 0.9972 - val_loss: 2.5433 - val_accuracy: 0.7000\n",
            "Epoch 378/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 2.4966 - val_accuracy: 0.7000\n",
            "Epoch 379/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 2.4476 - val_accuracy: 0.7125\n",
            "Epoch 380/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.5032 - val_accuracy: 0.7250\n",
            "Epoch 381/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 0.9972 - val_loss: 2.5383 - val_accuracy: 0.7125\n",
            "Epoch 382/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0103 - accuracy: 0.9944 - val_loss: 2.5402 - val_accuracy: 0.7250\n",
            "Epoch 383/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0106 - accuracy: 0.9958 - val_loss: 2.4585 - val_accuracy: 0.6875\n",
            "Epoch 384/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0052 - accuracy: 0.9972 - val_loss: 2.4543 - val_accuracy: 0.7000\n",
            "Epoch 385/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 2.5780 - val_accuracy: 0.7125\n",
            "Epoch 386/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0032 - accuracy: 0.9986 - val_loss: 2.7187 - val_accuracy: 0.7125\n",
            "Epoch 387/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 2.7324 - val_accuracy: 0.6875\n",
            "Epoch 388/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 2.7639 - val_accuracy: 0.6750\n",
            "Epoch 389/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 2.6114 - val_accuracy: 0.7000\n",
            "Epoch 390/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 2.5059 - val_accuracy: 0.7375\n",
            "Epoch 391/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.4995 - val_accuracy: 0.7375\n",
            "Epoch 392/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 2.4586 - val_accuracy: 0.7125\n",
            "Epoch 393/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0062 - accuracy: 0.9972 - val_loss: 2.4318 - val_accuracy: 0.7000\n",
            "Epoch 394/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0145 - accuracy: 0.9944 - val_loss: 2.4915 - val_accuracy: 0.7125\n",
            "Epoch 395/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0047 - accuracy: 0.9972 - val_loss: 2.5013 - val_accuracy: 0.7125\n",
            "Epoch 396/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0076 - accuracy: 0.9958 - val_loss: 2.6054 - val_accuracy: 0.7125\n",
            "Epoch 397/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 2.6543 - val_accuracy: 0.7250\n",
            "Epoch 398/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0290 - accuracy: 0.9944 - val_loss: 2.4145 - val_accuracy: 0.7500\n",
            "Epoch 399/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0071 - accuracy: 0.9972 - val_loss: 2.3848 - val_accuracy: 0.7625\n",
            "Epoch 400/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 2.3407 - val_accuracy: 0.7625\n",
            "Epoch 401/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0158 - accuracy: 0.9903 - val_loss: 2.8376 - val_accuracy: 0.6875\n",
            "Epoch 402/600\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.0267 - accuracy: 0.9958 - val_loss: 2.8130 - val_accuracy: 0.7125\n",
            "Epoch 403/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0044 - accuracy: 0.9972 - val_loss: 2.9919 - val_accuracy: 0.6875\n",
            "Epoch 404/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 2.7598 - val_accuracy: 0.6875\n",
            "Epoch 405/600\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 2.7489 - val_accuracy: 0.7000\n",
            "Epoch 406/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 2.7784 - val_accuracy: 0.7000\n",
            "Epoch 407/600\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 2.6794 - val_accuracy: 0.7125\n",
            "Epoch 408/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0048 - accuracy: 0.9972 - val_loss: 2.7164 - val_accuracy: 0.7125\n",
            "Epoch 409/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0034 - accuracy: 0.9986 - val_loss: 2.7717 - val_accuracy: 0.7125\n",
            "Epoch 410/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 2.8555 - val_accuracy: 0.6625\n",
            "Epoch 411/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0077 - accuracy: 0.9958 - val_loss: 2.9162 - val_accuracy: 0.6375\n",
            "Epoch 412/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0035 - accuracy: 0.9972 - val_loss: 2.9039 - val_accuracy: 0.6625\n",
            "Epoch 413/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 2.9043 - val_accuracy: 0.6750\n",
            "Epoch 414/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 2.8418 - val_accuracy: 0.6875\n",
            "Epoch 415/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0067 - accuracy: 0.9958 - val_loss: 2.8673 - val_accuracy: 0.7000\n",
            "Epoch 416/600\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0064 - accuracy: 0.9972 - val_loss: 2.9757 - val_accuracy: 0.6875\n",
            "Epoch 417/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0063 - accuracy: 0.9972 - val_loss: 2.9711 - val_accuracy: 0.7000\n",
            "Epoch 418/600\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 2.9746 - val_accuracy: 0.7125\n",
            "Epoch 419/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9898 - val_accuracy: 0.7125\n",
            "Epoch 420/600\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.0066 - accuracy: 0.9972 - val_loss: 2.9960 - val_accuracy: 0.7000\n",
            "Epoch 421/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0054 - accuracy: 0.9958 - val_loss: 3.0376 - val_accuracy: 0.6875\n",
            "Epoch 422/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 2.9709 - val_accuracy: 0.6750\n",
            "Epoch 423/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0049 - accuracy: 0.9972 - val_loss: 2.9596 - val_accuracy: 0.7000\n",
            "Epoch 424/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0038 - accuracy: 0.9972 - val_loss: 2.9539 - val_accuracy: 0.7000\n",
            "Epoch 425/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0104 - accuracy: 0.9958 - val_loss: 2.7261 - val_accuracy: 0.7500\n",
            "Epoch 426/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0152 - accuracy: 0.9944 - val_loss: 2.8795 - val_accuracy: 0.6875\n",
            "Epoch 427/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 2.9774 - val_accuracy: 0.7000\n",
            "Epoch 428/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0028 - accuracy: 0.9986 - val_loss: 3.0135 - val_accuracy: 0.7000\n",
            "Epoch 429/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.9958 - val_loss: 3.4006 - val_accuracy: 0.6625\n",
            "Epoch 430/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0123 - accuracy: 0.9931 - val_loss: 3.0502 - val_accuracy: 0.7125\n",
            "Epoch 431/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 0.9931 - val_loss: 3.1934 - val_accuracy: 0.6875\n",
            "Epoch 432/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0094 - accuracy: 0.9958 - val_loss: 3.1343 - val_accuracy: 0.7000\n",
            "Epoch 433/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0041 - accuracy: 0.9972 - val_loss: 3.0782 - val_accuracy: 0.7125\n",
            "Epoch 434/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0053 - accuracy: 0.9972 - val_loss: 3.0558 - val_accuracy: 0.7125\n",
            "Epoch 435/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 3.2363 - val_accuracy: 0.6750\n",
            "Epoch 436/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 3.0547 - val_accuracy: 0.6625\n",
            "Epoch 437/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 3.3116 - val_accuracy: 0.6750\n",
            "Epoch 438/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9931 - val_loss: 3.1915 - val_accuracy: 0.6875\n",
            "Epoch 439/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0095 - accuracy: 0.9958 - val_loss: 3.6390 - val_accuracy: 0.6500\n",
            "Epoch 440/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 3.6036 - val_accuracy: 0.6875\n",
            "Epoch 441/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0101 - accuracy: 0.9944 - val_loss: 3.2328 - val_accuracy: 0.7000\n",
            "Epoch 442/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0048 - accuracy: 0.9972 - val_loss: 3.1779 - val_accuracy: 0.7000\n",
            "Epoch 443/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 3.1429 - val_accuracy: 0.7125\n",
            "Epoch 444/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 3.3228 - val_accuracy: 0.6750\n",
            "Epoch 445/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0080 - accuracy: 0.9958 - val_loss: 3.3580 - val_accuracy: 0.6875\n",
            "Epoch 446/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0049 - accuracy: 0.9972 - val_loss: 3.6092 - val_accuracy: 0.6625\n",
            "Epoch 447/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 3.6083 - val_accuracy: 0.6875\n",
            "Epoch 448/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0058 - accuracy: 0.9972 - val_loss: 3.4773 - val_accuracy: 0.6875\n",
            "Epoch 449/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0039 - accuracy: 0.9972 - val_loss: 3.3446 - val_accuracy: 0.7125\n",
            "Epoch 450/600\n",
            "23/23 [==============================] - 0s 21ms/step - loss: 0.0067 - accuracy: 0.9972 - val_loss: 3.3073 - val_accuracy: 0.7125\n",
            "Epoch 451/600\n",
            "23/23 [==============================] - 0s 21ms/step - loss: 0.0063 - accuracy: 0.9972 - val_loss: 3.3462 - val_accuracy: 0.7000\n",
            "Epoch 452/600\n",
            "23/23 [==============================] - 1s 22ms/step - loss: 0.0065 - accuracy: 0.9972 - val_loss: 3.4235 - val_accuracy: 0.6875\n",
            "Epoch 453/600\n",
            "23/23 [==============================] - 0s 20ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 3.2090 - val_accuracy: 0.7000\n",
            "Epoch 454/600\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.0036 - accuracy: 0.9972 - val_loss: 3.1155 - val_accuracy: 0.7250\n",
            "Epoch 455/600\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.1058 - val_accuracy: 0.7250\n",
            "Epoch 456/600\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 3.2221 - val_accuracy: 0.7125\n",
            "Epoch 457/600\n",
            "23/23 [==============================] - 1s 31ms/step - loss: 0.0167 - accuracy: 0.9944 - val_loss: 2.8637 - val_accuracy: 0.7500\n",
            "Epoch 458/600\n",
            "23/23 [==============================] - 1s 32ms/step - loss: 0.0120 - accuracy: 0.9972 - val_loss: 3.0114 - val_accuracy: 0.7375\n",
            "Epoch 459/600\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 3.0152 - val_accuracy: 0.7250\n",
            "Epoch 460/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0065 - accuracy: 0.9958 - val_loss: 3.0081 - val_accuracy: 0.7250\n",
            "Epoch 461/600\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.0189 - accuracy: 0.9958 - val_loss: 3.0512 - val_accuracy: 0.7125\n",
            "Epoch 462/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0193 - accuracy: 0.9944 - val_loss: 3.3208 - val_accuracy: 0.7125\n",
            "Epoch 463/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0247 - accuracy: 0.9944 - val_loss: 3.3793 - val_accuracy: 0.6750\n",
            "Epoch 464/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 3.0620 - val_accuracy: 0.7125\n",
            "Epoch 465/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 3.0412 - val_accuracy: 0.7000\n",
            "Epoch 466/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 2.8746 - val_accuracy: 0.7125\n",
            "Epoch 467/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.8772 - val_accuracy: 0.7250\n",
            "Epoch 468/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0044 - accuracy: 0.9972 - val_loss: 2.8536 - val_accuracy: 0.7250\n",
            "Epoch 469/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0112 - accuracy: 0.9917 - val_loss: 3.0508 - val_accuracy: 0.6875\n",
            "Epoch 470/600\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.0289 - accuracy: 0.9944 - val_loss: 3.1757 - val_accuracy: 0.7000\n",
            "Epoch 471/600\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.0150 - accuracy: 0.9958 - val_loss: 3.3911 - val_accuracy: 0.7000\n",
            "Epoch 472/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0162 - accuracy: 0.9972 - val_loss: 3.2496 - val_accuracy: 0.6875\n",
            "Epoch 473/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0098 - accuracy: 0.9944 - val_loss: 3.1563 - val_accuracy: 0.7000\n",
            "Epoch 474/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0137 - accuracy: 0.9931 - val_loss: 3.1370 - val_accuracy: 0.7125\n",
            "Epoch 475/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0060 - accuracy: 0.9972 - val_loss: 3.2365 - val_accuracy: 0.6625\n",
            "Epoch 476/600\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 3.2352 - val_accuracy: 0.6625\n",
            "Epoch 477/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 0.9972 - val_loss: 3.4901 - val_accuracy: 0.6750\n",
            "Epoch 478/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0072 - accuracy: 0.9972 - val_loss: 3.0921 - val_accuracy: 0.7000\n",
            "Epoch 479/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 3.0439 - val_accuracy: 0.7000\n",
            "Epoch 480/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 3.0830 - val_accuracy: 0.6875\n",
            "Epoch 481/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.9958 - val_loss: 3.1059 - val_accuracy: 0.6875\n",
            "Epoch 482/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0230 - accuracy: 0.9958 - val_loss: 3.1534 - val_accuracy: 0.6875\n",
            "Epoch 483/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9931 - val_loss: 3.2649 - val_accuracy: 0.6750\n",
            "Epoch 484/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0105 - accuracy: 0.9958 - val_loss: 3.2566 - val_accuracy: 0.6625\n",
            "Epoch 485/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 3.3690 - val_accuracy: 0.6625\n",
            "Epoch 486/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0160 - accuracy: 0.9944 - val_loss: 3.0914 - val_accuracy: 0.6875\n",
            "Epoch 487/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0217 - accuracy: 0.9958 - val_loss: 3.0482 - val_accuracy: 0.7000\n",
            "Epoch 488/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0056 - accuracy: 0.9972 - val_loss: 3.1351 - val_accuracy: 0.6875\n",
            "Epoch 489/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 3.1746 - val_accuracy: 0.7000\n",
            "Epoch 490/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0059 - accuracy: 0.9958 - val_loss: 3.1615 - val_accuracy: 0.6875\n",
            "Epoch 491/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0053 - accuracy: 0.9972 - val_loss: 3.1825 - val_accuracy: 0.6750\n",
            "Epoch 492/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 3.1495 - val_accuracy: 0.7000\n",
            "Epoch 493/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0263 - accuracy: 0.9958 - val_loss: 3.0455 - val_accuracy: 0.6750\n",
            "Epoch 494/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.2621 - val_accuracy: 0.6875\n",
            "Epoch 495/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0245 - accuracy: 0.9917 - val_loss: 3.1999 - val_accuracy: 0.6500\n",
            "Epoch 496/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0062 - accuracy: 0.9958 - val_loss: 2.9771 - val_accuracy: 0.6750\n",
            "Epoch 497/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 2.9831 - val_accuracy: 0.6750\n",
            "Epoch 498/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 3.1623 - val_accuracy: 0.6750\n",
            "Epoch 499/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0148 - accuracy: 0.9931 - val_loss: 2.8599 - val_accuracy: 0.7000\n",
            "Epoch 500/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0060 - accuracy: 0.9958 - val_loss: 2.7857 - val_accuracy: 0.7250\n",
            "Epoch 501/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 2.8291 - val_accuracy: 0.7125\n",
            "Epoch 502/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0136 - accuracy: 0.9931 - val_loss: 3.0859 - val_accuracy: 0.6875\n",
            "Epoch 503/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0091 - accuracy: 0.9931 - val_loss: 2.8929 - val_accuracy: 0.6875\n",
            "Epoch 504/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 2.9504 - val_accuracy: 0.7000\n",
            "Epoch 505/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0243 - accuracy: 0.9917 - val_loss: 2.9944 - val_accuracy: 0.6750\n",
            "Epoch 506/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0028 - accuracy: 0.9986 - val_loss: 3.0422 - val_accuracy: 0.6875\n",
            "Epoch 507/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 3.1694 - val_accuracy: 0.6625\n",
            "Epoch 508/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0069 - accuracy: 0.9972 - val_loss: 2.9511 - val_accuracy: 0.6625\n",
            "Epoch 509/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 2.9977 - val_accuracy: 0.6750\n",
            "Epoch 510/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0097 - accuracy: 0.9958 - val_loss: 3.0150 - val_accuracy: 0.7000\n",
            "Epoch 511/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0037 - accuracy: 0.9972 - val_loss: 2.8979 - val_accuracy: 0.6875\n",
            "Epoch 512/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 2.8041 - val_accuracy: 0.7500\n",
            "Epoch 513/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0089 - accuracy: 0.9986 - val_loss: 2.9608 - val_accuracy: 0.7250\n",
            "Epoch 514/600\n",
            "23/23 [==============================] - 0s 20ms/step - loss: 0.0140 - accuracy: 0.9917 - val_loss: 2.7170 - val_accuracy: 0.7250\n",
            "Epoch 515/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0107 - accuracy: 0.9958 - val_loss: 3.2725 - val_accuracy: 0.6500\n",
            "Epoch 516/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0116 - accuracy: 0.9944 - val_loss: 2.9278 - val_accuracy: 0.6750\n",
            "Epoch 517/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0058 - accuracy: 0.9944 - val_loss: 2.7956 - val_accuracy: 0.6875\n",
            "Epoch 518/600\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.0076 - accuracy: 0.9944 - val_loss: 3.0361 - val_accuracy: 0.6750\n",
            "Epoch 519/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0138 - accuracy: 0.9986 - val_loss: 3.2061 - val_accuracy: 0.6625\n",
            "Epoch 520/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0195 - accuracy: 0.9986 - val_loss: 3.4243 - val_accuracy: 0.6625\n",
            "Epoch 521/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0186 - accuracy: 0.9944 - val_loss: 3.4251 - val_accuracy: 0.6750\n",
            "Epoch 522/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 3.4445 - val_accuracy: 0.6625\n",
            "Epoch 523/600\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.0094 - accuracy: 0.9958 - val_loss: 3.3411 - val_accuracy: 0.6750\n",
            "Epoch 524/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0334 - accuracy: 0.9903 - val_loss: 3.2014 - val_accuracy: 0.6875\n",
            "Epoch 525/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 3.4421 - val_accuracy: 0.6750\n",
            "Epoch 526/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0177 - accuracy: 0.9958 - val_loss: 3.3770 - val_accuracy: 0.6750\n",
            "Epoch 527/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0159 - accuracy: 0.9944 - val_loss: 3.1675 - val_accuracy: 0.6875\n",
            "Epoch 528/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0321 - accuracy: 0.9931 - val_loss: 2.7753 - val_accuracy: 0.6625\n",
            "Epoch 529/600\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 2.6628 - val_accuracy: 0.6625\n",
            "Epoch 530/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0066 - accuracy: 0.9972 - val_loss: 2.7352 - val_accuracy: 0.6750\n",
            "Epoch 531/600\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0048 - accuracy: 0.9972 - val_loss: 2.8428 - val_accuracy: 0.6875\n",
            "Epoch 532/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0053 - accuracy: 0.9972 - val_loss: 2.8152 - val_accuracy: 0.6875\n",
            "Epoch 533/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0031 - accuracy: 0.9986 - val_loss: 2.8229 - val_accuracy: 0.6875\n",
            "Epoch 534/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 2.7560 - val_accuracy: 0.7000\n",
            "Epoch 535/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 2.7633 - val_accuracy: 0.7000\n",
            "Epoch 536/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0044 - accuracy: 0.9958 - val_loss: 2.7625 - val_accuracy: 0.7000\n",
            "Epoch 537/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 0.9958 - val_loss: 2.7839 - val_accuracy: 0.7000\n",
            "Epoch 538/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0029 - accuracy: 0.9986 - val_loss: 2.8190 - val_accuracy: 0.6875\n",
            "Epoch 539/600\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 2.9356 - val_accuracy: 0.6875\n",
            "Epoch 540/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9972 - val_loss: 2.6834 - val_accuracy: 0.7125\n",
            "Epoch 541/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 2.6962 - val_accuracy: 0.6875\n",
            "Epoch 542/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0027 - accuracy: 0.9986 - val_loss: 2.7231 - val_accuracy: 0.6750\n",
            "Epoch 543/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 2.4914 - val_accuracy: 0.6875\n",
            "Epoch 544/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 0.9972 - val_loss: 2.4446 - val_accuracy: 0.7000\n",
            "Epoch 545/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0048 - accuracy: 0.9972 - val_loss: 2.5056 - val_accuracy: 0.6750\n",
            "Epoch 546/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0045 - accuracy: 0.9972 - val_loss: 2.5914 - val_accuracy: 0.7000\n",
            "Epoch 547/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0034 - accuracy: 0.9986 - val_loss: 2.6588 - val_accuracy: 0.7125\n",
            "Epoch 548/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0030 - accuracy: 0.9986 - val_loss: 2.6727 - val_accuracy: 0.7125\n",
            "Epoch 549/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0055 - accuracy: 0.9958 - val_loss: 2.5622 - val_accuracy: 0.7125\n",
            "Epoch 550/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0124 - accuracy: 0.9972 - val_loss: 2.7204 - val_accuracy: 0.6625\n",
            "Epoch 551/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0053 - accuracy: 0.9972 - val_loss: 2.6652 - val_accuracy: 0.6625\n",
            "Epoch 552/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0083 - accuracy: 0.9958 - val_loss: 2.7676 - val_accuracy: 0.7125\n",
            "Epoch 553/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0064 - accuracy: 0.9972 - val_loss: 2.7146 - val_accuracy: 0.7125\n",
            "Epoch 554/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 3.1439 - val_accuracy: 0.7250\n",
            "Epoch 555/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0086 - accuracy: 0.9958 - val_loss: 3.1818 - val_accuracy: 0.6625\n",
            "Epoch 556/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 0.9958 - val_loss: 3.1905 - val_accuracy: 0.6875\n",
            "Epoch 557/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0113 - accuracy: 0.9972 - val_loss: 3.3198 - val_accuracy: 0.6750\n",
            "Epoch 558/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0051 - accuracy: 0.9972 - val_loss: 3.3285 - val_accuracy: 0.6750\n",
            "Epoch 559/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0109 - accuracy: 0.9986 - val_loss: 3.1492 - val_accuracy: 0.7000\n",
            "Epoch 560/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 3.2020 - val_accuracy: 0.7000\n",
            "Epoch 561/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0060 - accuracy: 0.9958 - val_loss: 3.1792 - val_accuracy: 0.7000\n",
            "Epoch 562/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.9958 - val_loss: 3.1412 - val_accuracy: 0.7125\n",
            "Epoch 563/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 2.9982 - val_accuracy: 0.7125\n",
            "Epoch 564/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0028 - accuracy: 0.9972 - val_loss: 2.9442 - val_accuracy: 0.7125\n",
            "Epoch 565/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0034 - accuracy: 0.9972 - val_loss: 2.9278 - val_accuracy: 0.7125\n",
            "Epoch 566/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9278 - val_accuracy: 0.7125\n",
            "Epoch 567/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 0.9972 - val_loss: 2.9122 - val_accuracy: 0.7125\n",
            "Epoch 568/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0027 - accuracy: 0.9986 - val_loss: 2.9117 - val_accuracy: 0.7125\n",
            "Epoch 569/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0023 - accuracy: 0.9986 - val_loss: 2.8973 - val_accuracy: 0.7000\n",
            "Epoch 570/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0032 - accuracy: 0.9972 - val_loss: 2.8949 - val_accuracy: 0.7000\n",
            "Epoch 571/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.9986 - val_loss: 2.9008 - val_accuracy: 0.7000\n",
            "Epoch 572/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 2.7163 - val_accuracy: 0.7250\n",
            "Epoch 573/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0071 - accuracy: 0.9972 - val_loss: 2.8142 - val_accuracy: 0.7125\n",
            "Epoch 574/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0062 - accuracy: 0.9958 - val_loss: 2.8013 - val_accuracy: 0.7125\n",
            "Epoch 575/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 2.8698 - val_accuracy: 0.6625\n",
            "Epoch 576/600\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0267 - accuracy: 0.9944 - val_loss: 3.1406 - val_accuracy: 0.6750\n",
            "Epoch 577/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0084 - accuracy: 0.9944 - val_loss: 3.2205 - val_accuracy: 0.6500\n",
            "Epoch 578/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 3.4293 - val_accuracy: 0.6750\n",
            "Epoch 579/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0082 - accuracy: 0.9958 - val_loss: 3.3420 - val_accuracy: 0.6625\n",
            "Epoch 580/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 3.2920 - val_accuracy: 0.6375\n",
            "Epoch 581/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0028 - accuracy: 0.9986 - val_loss: 3.2931 - val_accuracy: 0.6375\n",
            "Epoch 582/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.3526 - val_accuracy: 0.6375\n",
            "Epoch 583/600\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.0047 - accuracy: 0.9972 - val_loss: 3.0784 - val_accuracy: 0.6875\n",
            "Epoch 584/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0107 - accuracy: 0.9958 - val_loss: 3.0636 - val_accuracy: 0.6875\n",
            "Epoch 585/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.4447 - val_accuracy: 0.6625\n",
            "Epoch 586/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0037 - accuracy: 0.9972 - val_loss: 3.5017 - val_accuracy: 0.6750\n",
            "Epoch 587/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0032 - accuracy: 0.9986 - val_loss: 3.4478 - val_accuracy: 0.6750\n",
            "Epoch 588/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 0.9986 - val_loss: 3.4736 - val_accuracy: 0.6750\n",
            "Epoch 589/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0138 - accuracy: 0.9972 - val_loss: 3.2387 - val_accuracy: 0.6875\n",
            "Epoch 590/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0024 - accuracy: 0.9986 - val_loss: 3.2641 - val_accuracy: 0.7000\n",
            "Epoch 591/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0034 - accuracy: 0.9972 - val_loss: 3.2949 - val_accuracy: 0.7000\n",
            "Epoch 592/600\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0060 - accuracy: 0.9972 - val_loss: 3.1192 - val_accuracy: 0.7000\n",
            "Epoch 593/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0042 - accuracy: 0.9972 - val_loss: 3.0136 - val_accuracy: 0.7000\n",
            "Epoch 594/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0024 - accuracy: 0.9986 - val_loss: 3.0059 - val_accuracy: 0.7000\n",
            "Epoch 595/600\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0095 - accuracy: 0.9958 - val_loss: 2.9374 - val_accuracy: 0.7250\n",
            "Epoch 596/600\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.0140 - val_accuracy: 0.7125\n",
            "Epoch 597/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.9944 - val_loss: 3.0730 - val_accuracy: 0.7125\n",
            "Epoch 598/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0029 - accuracy: 0.9986 - val_loss: 3.0173 - val_accuracy: 0.7125\n",
            "Epoch 599/600\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 0.9972 - val_loss: 3.0567 - val_accuracy: 0.7125\n",
            "Epoch 600/600\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0064 - accuracy: 0.9958 - val_loss: 3.0516 - val_accuracy: 0.7250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test_reshaped)  # Make predictions on the scaled test data\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "accuracy = accuracy_score(y_test_encoded, y_pred_labels)  # Calculate accuracy\n",
        "report = classification_report(y_test_encoded, y_pred_labels)  # Generate a detailed classification report\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGJbtKIX6du5",
        "outputId": "55fb53ad-df4f-4250-9937-27f040be07d0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 1s 4ms/step\n",
            "Accuracy: 0.705\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.85      0.71        20\n",
            "           1       0.92      0.85      0.88        13\n",
            "           2       0.82      0.67      0.73        27\n",
            "           3       0.60      0.57      0.59        21\n",
            "           4       0.57      0.80      0.67        15\n",
            "           5       0.77      0.77      0.77        22\n",
            "           6       0.78      0.84      0.81        25\n",
            "           7       0.83      0.77      0.80        13\n",
            "           8       0.59      0.43      0.50        23\n",
            "           9       0.68      0.62      0.65        21\n",
            "\n",
            "    accuracy                           0.70       200\n",
            "   macro avg       0.72      0.72      0.71       200\n",
            "weighted avg       0.71      0.70      0.70       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('rnn_model2_epochs600_batch32.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sps3iJa_7YvU",
        "outputId": "9d550667-d6d6-4d3e-a014-d0df45a16fb1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##So it is quite visible we are overfitting\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Build the LSTM model with additional dropout and early stopping\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=128, input_shape=(num_timesteps, X_train_reshaped.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.3))  # Increase dropout for regularization\n",
        "\n",
        "model.add(LSTM(units=64, return_sequences=True))\n",
        "model.add(Dropout(0.3))  # Increase dropout for regularization\n",
        "\n",
        "model.add(LSTM(units=32))\n",
        "model.add(Dropout(0.3))  # Increase dropout for regularization\n",
        "\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dense(units=len(labels.unique()), activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Implement early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train_encoded, epochs=600, batch_size=16, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwfvJ9Yt7ie2",
        "outputId": "74f1d3a5-ef0e-46ed-b004-dc71872c36b7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "45/45 [==============================] - 10s 41ms/step - loss: 2.2722 - accuracy: 0.2556 - val_loss: 2.1796 - val_accuracy: 0.3500\n",
            "Epoch 2/600\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 1.9485 - accuracy: 0.3236 - val_loss: 1.7240 - val_accuracy: 0.2875\n",
            "Epoch 3/600\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 1.6472 - accuracy: 0.3306 - val_loss: 1.5545 - val_accuracy: 0.3125\n",
            "Epoch 4/600\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 1.4652 - accuracy: 0.4194 - val_loss: 1.3991 - val_accuracy: 0.4625\n",
            "Epoch 5/600\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 1.3191 - accuracy: 0.4986 - val_loss: 1.2895 - val_accuracy: 0.4750\n",
            "Epoch 6/600\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 1.2220 - accuracy: 0.4958 - val_loss: 1.1994 - val_accuracy: 0.5375\n",
            "Epoch 7/600\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 1.1137 - accuracy: 0.5847 - val_loss: 1.1041 - val_accuracy: 0.5625\n",
            "Epoch 8/600\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 1.0211 - accuracy: 0.6153 - val_loss: 1.0986 - val_accuracy: 0.5375\n",
            "Epoch 9/600\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.9521 - accuracy: 0.6403 - val_loss: 1.0149 - val_accuracy: 0.5375\n",
            "Epoch 10/600\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.8857 - accuracy: 0.6736 - val_loss: 0.8914 - val_accuracy: 0.6375\n",
            "Epoch 11/600\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8184 - accuracy: 0.7083 - val_loss: 0.8560 - val_accuracy: 0.6625\n",
            "Epoch 12/600\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.7173 - accuracy: 0.7528 - val_loss: 0.8409 - val_accuracy: 0.6750\n",
            "Epoch 13/600\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.7043 - accuracy: 0.7639 - val_loss: 0.7957 - val_accuracy: 0.6875\n",
            "Epoch 14/600\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.6580 - accuracy: 0.7792 - val_loss: 0.8556 - val_accuracy: 0.6750\n",
            "Epoch 15/600\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.5902 - accuracy: 0.8014 - val_loss: 0.8266 - val_accuracy: 0.7125\n",
            "Epoch 16/600\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.5780 - accuracy: 0.8042 - val_loss: 0.7796 - val_accuracy: 0.7250\n",
            "Epoch 17/600\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.5531 - accuracy: 0.8167 - val_loss: 0.8527 - val_accuracy: 0.6750\n",
            "Epoch 18/600\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.4817 - accuracy: 0.8403 - val_loss: 0.7330 - val_accuracy: 0.7250\n",
            "Epoch 19/600\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.4775 - accuracy: 0.8472 - val_loss: 0.7486 - val_accuracy: 0.7000\n",
            "Epoch 20/600\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.4607 - accuracy: 0.8389 - val_loss: 0.8319 - val_accuracy: 0.7125\n",
            "Epoch 21/600\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.4063 - accuracy: 0.8625 - val_loss: 0.8632 - val_accuracy: 0.7125\n",
            "Epoch 22/600\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.3705 - accuracy: 0.8917 - val_loss: 0.8524 - val_accuracy: 0.7125\n",
            "Epoch 23/600\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.4147 - accuracy: 0.8472 - val_loss: 0.8353 - val_accuracy: 0.7000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test_reshaped)  # Make predictions on the scaled test data\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "accuracy = accuracy_score(y_test_encoded, y_pred_labels)  # Calculate accuracy\n",
        "report = classification_report(y_test_encoded, y_pred_labels)  # Generate a detailed classification report\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVfqy6XR8zlw",
        "outputId": "3489fc18-0158-4b0e-8a5b-4f1981866e06"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 1s 3ms/step\n",
            "Accuracy: 0.705\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.85      0.79        20\n",
            "           1       0.92      0.92      0.92        13\n",
            "           2       0.78      0.67      0.72        27\n",
            "           3       0.43      0.48      0.45        21\n",
            "           4       0.71      0.80      0.75        15\n",
            "           5       0.90      0.86      0.88        22\n",
            "           6       0.82      0.92      0.87        25\n",
            "           7       0.62      0.77      0.69        13\n",
            "           8       0.69      0.48      0.56        23\n",
            "           9       0.45      0.43      0.44        21\n",
            "\n",
            "    accuracy                           0.70       200\n",
            "   macro avg       0.71      0.72      0.71       200\n",
            "weighted avg       0.71      0.70      0.70       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('rnn_model3_epochs600_batch32_dropout.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRsQ_Jx286Zg",
        "outputId": "e6766ecc-e449-4c5a-a299-26dcb2bc8e68"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(units=64, input_shape=(num_timesteps, X_train_reshaped.shape[2]), return_sequences=True))\n",
        "\n",
        "model.add(LSTM(units=64, return_sequences=True))  # If you intend to add another LSTM layer after this\n",
        "\n",
        "# Add a Dropout layer after LSTM(s)\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Add Dense layer(s) or output layer\n",
        "model.add(Dense(units=len(labels.unique()), activation='softmax'))  # Output layer with softmax for classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Implement early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train_encoded, epochs=600, batch_size=128, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00QauP259iul",
        "outputId": "616491ff-bfa1-473a-cf92-016e9b8bf5fa"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "6/6 [==============================] - 9s 196ms/step - loss: 2.2884 - accuracy: 0.1010 - val_loss: 2.2723 - val_accuracy: 0.1025\n",
            "Epoch 2/600\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 2.2538 - accuracy: 0.1048 - val_loss: 2.2397 - val_accuracy: 0.1022\n",
            "Epoch 3/600\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 2.2154 - accuracy: 0.1066 - val_loss: 2.2000 - val_accuracy: 0.0986\n",
            "Epoch 4/600\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 2.1644 - accuracy: 0.1055 - val_loss: 2.1499 - val_accuracy: 0.0966\n",
            "Epoch 5/600\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 2.1022 - accuracy: 0.1047 - val_loss: 2.0878 - val_accuracy: 0.0958\n",
            "Epoch 6/600\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 2.0312 - accuracy: 0.1047 - val_loss: 2.0150 - val_accuracy: 0.0950\n",
            "Epoch 7/600\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 1.9461 - accuracy: 0.1041 - val_loss: 1.9375 - val_accuracy: 0.0950\n",
            "Epoch 8/600\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 1.8620 - accuracy: 0.1046 - val_loss: 1.8610 - val_accuracy: 0.0942\n",
            "Epoch 9/600\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 1.7830 - accuracy: 0.1075 - val_loss: 1.7934 - val_accuracy: 0.0942\n",
            "Epoch 10/600\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.7153 - accuracy: 0.1048 - val_loss: 1.7351 - val_accuracy: 0.0948\n",
            "Epoch 11/600\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.6560 - accuracy: 0.1040 - val_loss: 1.6802 - val_accuracy: 0.0948\n",
            "Epoch 12/600\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.6055 - accuracy: 0.1048 - val_loss: 1.6256 - val_accuracy: 0.0950\n",
            "Epoch 13/600\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 1.5411 - accuracy: 0.1048 - val_loss: 1.5727 - val_accuracy: 0.0980\n",
            "Epoch 14/600\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.4928 - accuracy: 0.1045 - val_loss: 1.5197 - val_accuracy: 0.0998\n",
            "Epoch 15/600\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.4399 - accuracy: 0.1043 - val_loss: 1.4700 - val_accuracy: 0.1017\n",
            "Epoch 16/600\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 1.3982 - accuracy: 0.1034 - val_loss: 1.4233 - val_accuracy: 0.1019\n",
            "Epoch 17/600\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 1.3428 - accuracy: 0.1043 - val_loss: 1.3774 - val_accuracy: 0.1023\n",
            "Epoch 18/600\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 1.3020 - accuracy: 0.1064 - val_loss: 1.3366 - val_accuracy: 0.1022\n",
            "Epoch 19/600\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 1.2463 - accuracy: 0.1034 - val_loss: 1.2958 - val_accuracy: 0.1034\n",
            "Epoch 20/600\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 1.2110 - accuracy: 0.1031 - val_loss: 1.2571 - val_accuracy: 0.1025\n",
            "Epoch 21/600\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 1.1689 - accuracy: 0.1032 - val_loss: 1.2229 - val_accuracy: 0.1025\n",
            "Epoch 22/600\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 1.1306 - accuracy: 0.1034 - val_loss: 1.1914 - val_accuracy: 0.1011\n",
            "Epoch 23/600\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.0882 - accuracy: 0.1046 - val_loss: 1.1596 - val_accuracy: 0.1009\n",
            "Epoch 24/600\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 1.0423 - accuracy: 0.1069 - val_loss: 1.1272 - val_accuracy: 0.1022\n",
            "Epoch 25/600\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 1.0092 - accuracy: 0.1047 - val_loss: 1.0935 - val_accuracy: 0.1020\n",
            "Epoch 26/600\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.9645 - accuracy: 0.1047 - val_loss: 1.0683 - val_accuracy: 0.1017\n",
            "Epoch 27/600\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.9201 - accuracy: 0.1032 - val_loss: 1.0410 - val_accuracy: 0.1019\n",
            "Epoch 28/600\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.8813 - accuracy: 0.1039 - val_loss: 1.0147 - val_accuracy: 0.1006\n",
            "Epoch 29/600\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.8439 - accuracy: 0.1041 - val_loss: 0.9930 - val_accuracy: 0.1006\n",
            "Epoch 30/600\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.8114 - accuracy: 0.1059 - val_loss: 0.9701 - val_accuracy: 0.1009\n",
            "Epoch 31/600\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.7828 - accuracy: 0.1056 - val_loss: 0.9504 - val_accuracy: 0.1014\n",
            "Epoch 32/600\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.7382 - accuracy: 0.1035 - val_loss: 0.9342 - val_accuracy: 0.1009\n",
            "Epoch 33/600\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.7130 - accuracy: 0.1063 - val_loss: 0.9152 - val_accuracy: 0.1014\n",
            "Epoch 34/600\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6866 - accuracy: 0.1062 - val_loss: 0.8969 - val_accuracy: 0.1023\n",
            "Epoch 35/600\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6551 - accuracy: 0.1048 - val_loss: 0.8856 - val_accuracy: 0.1023\n",
            "Epoch 36/600\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.6304 - accuracy: 0.1048 - val_loss: 0.8722 - val_accuracy: 0.1017\n",
            "Epoch 37/600\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6004 - accuracy: 0.1046 - val_loss: 0.8554 - val_accuracy: 0.1022\n",
            "Epoch 38/600\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.5906 - accuracy: 0.1061 - val_loss: 0.8426 - val_accuracy: 0.1028\n",
            "Epoch 39/600\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.5648 - accuracy: 0.1053 - val_loss: 0.8260 - val_accuracy: 0.1028\n",
            "Epoch 40/600\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.5286 - accuracy: 0.1057 - val_loss: 0.8148 - val_accuracy: 0.1028\n",
            "Epoch 41/600\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.5053 - accuracy: 0.1038 - val_loss: 0.8101 - val_accuracy: 0.1028\n",
            "Epoch 42/600\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.4928 - accuracy: 0.1044 - val_loss: 0.7966 - val_accuracy: 0.1028\n",
            "Epoch 43/600\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.4678 - accuracy: 0.1062 - val_loss: 0.7919 - val_accuracy: 0.1030\n",
            "Epoch 44/600\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.4465 - accuracy: 0.1070 - val_loss: 0.7858 - val_accuracy: 0.1027\n",
            "Epoch 45/600\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.4322 - accuracy: 0.1063 - val_loss: 0.7827 - val_accuracy: 0.1028\n",
            "Epoch 46/600\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.4148 - accuracy: 0.1048 - val_loss: 0.7787 - val_accuracy: 0.1025\n",
            "Epoch 47/600\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.4103 - accuracy: 0.1071 - val_loss: 0.7698 - val_accuracy: 0.1025\n",
            "Epoch 48/600\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3900 - accuracy: 0.1086 - val_loss: 0.7600 - val_accuracy: 0.1013\n",
            "Epoch 49/600\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3631 - accuracy: 0.1073 - val_loss: 0.7580 - val_accuracy: 0.1013\n",
            "Epoch 50/600\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3588 - accuracy: 0.1054 - val_loss: 0.7559 - val_accuracy: 0.1013\n",
            "Epoch 51/600\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.3479 - accuracy: 0.1056 - val_loss: 0.7471 - val_accuracy: 0.1013\n",
            "Epoch 52/600\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3315 - accuracy: 0.1061 - val_loss: 0.7385 - val_accuracy: 0.1023\n",
            "Epoch 53/600\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3183 - accuracy: 0.1050 - val_loss: 0.7434 - val_accuracy: 0.1020\n",
            "Epoch 54/600\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.3049 - accuracy: 0.1047 - val_loss: 0.7411 - val_accuracy: 0.1013\n",
            "Epoch 55/600\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.2868 - accuracy: 0.1063 - val_loss: 0.7398 - val_accuracy: 0.1017\n",
            "Epoch 56/600\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2818 - accuracy: 0.1062 - val_loss: 0.7334 - val_accuracy: 0.1025\n",
            "Epoch 57/600\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2640 - accuracy: 0.1076 - val_loss: 0.7300 - val_accuracy: 0.1031\n",
            "Epoch 58/600\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2600 - accuracy: 0.1047 - val_loss: 0.7186 - val_accuracy: 0.1033\n",
            "Epoch 59/600\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2395 - accuracy: 0.1052 - val_loss: 0.7229 - val_accuracy: 0.1022\n",
            "Epoch 60/600\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.2368 - accuracy: 0.1089 - val_loss: 0.7258 - val_accuracy: 0.1037\n",
            "Epoch 61/600\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2299 - accuracy: 0.1059 - val_loss: 0.7183 - val_accuracy: 0.1037\n",
            "Epoch 62/600\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.2159 - accuracy: 0.1046 - val_loss: 0.7205 - val_accuracy: 0.1037\n",
            "Epoch 63/600\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2104 - accuracy: 0.1056 - val_loss: 0.7120 - val_accuracy: 0.1037\n",
            "Epoch 64/600\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1893 - accuracy: 0.1064 - val_loss: 0.7067 - val_accuracy: 0.1039\n",
            "Epoch 65/600\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1815 - accuracy: 0.1061 - val_loss: 0.7200 - val_accuracy: 0.1031\n",
            "Epoch 66/600\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.1849 - accuracy: 0.1059 - val_loss: 0.7263 - val_accuracy: 0.1044\n",
            "Epoch 67/600\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1804 - accuracy: 0.1067 - val_loss: 0.7282 - val_accuracy: 0.1044\n",
            "Epoch 68/600\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1722 - accuracy: 0.1077 - val_loss: 0.7321 - val_accuracy: 0.1047\n",
            "Epoch 69/600\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.1586 - accuracy: 0.1063 - val_loss: 0.7350 - val_accuracy: 0.1044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Convert the format of y_test_encoded to an array of integers if needed\n",
        "y_test_encoded = np.array(y_test_encoded)\n",
        "\n",
        "# Ensure y_pred_labels contains integers representing predicted classes\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Calculate accuracy and generate a classification report\n",
        "accuracy = accuracy_score(y_test_encoded, y_pred_labels)\n",
        "report = classification_report(y_test_encoded, y_pred_labels)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "MqQ4_Hbw-evw",
        "outputId": "9b44ee51-13db-4870-ea68-56d5153daa12"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-1ec9b7f26c87>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Calculate accuracy and generate a classification report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     96\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     97\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and multilabel-indicator targets"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "test_loss, test_acc = model.evaluate(X_test_reshaped, y_test_encoded)\n",
        "print(f'Test accuracy: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCeggDAM-iw0",
        "outputId": "791f08a0-3d8b-4e53-ca6a-12d5b9f2af77"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 6ms/step - loss: 0.9908 - accuracy: 0.1144\n",
            "Test accuracy: 0.11436855792999268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lq_H2S2HBFeC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}